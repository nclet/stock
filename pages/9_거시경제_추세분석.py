import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import os
import requests
import xmltodict
import time # ì‹œê°„ ì§€ì—°ì„ ìœ„í•´ ì¶”ê°€
import random # ë¬´ì‘ìœ„ ì‹œê°„ ì§€ì—°ì„ ìœ„í•´ ì¶”ê°€

# FinanceDataReader ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ (KOSPI ë°ì´í„°ìš©)
try:
    import FinanceDataReader as fdr
except ImportError:
    st.error("""
    FinanceDataReader ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!
    `pip install FinanceDataReader` ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.
    """)
    st.stop()


# FRED ë° ECOS API í‚¤ ë¡œë“œ (secrets.tomlì—ì„œ)
try:
    FRED_API_KEY = st.secrets["FRED_API_KEY"]
    ECOS_API_KEY = st.secrets["ECOS_API_KEY"]
    import pandas_datareader.data as web # pandas_datareaderëŠ” FREDìš©ìœ¼ë¡œ ìœ ì§€
except ImportError:
    st.error("""
    **í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!**
    `pip install pandas_datareader requests xmltodict matplotlib seaborn` ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ê³ ,
    `.streamlit/secrets.toml` íŒŒì¼ì— FRED_API_KEYì™€ ECOS_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.
    """)
    st.stop()
except KeyError:
    st.error("""
    **FRED ë˜ëŠ” ECOS API í‚¤ê°€ Streamlit Secretsì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!**
    `.streamlit/secrets.toml` íŒŒì¼ì— ì•„ë˜ ë‚´ìš©ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”:
    FRED_API_KEY = "YOUR_FRED_API_KEY"
    ECOS_API_KEY = "YOUR_ECOS_API_KEY"
    """)
    st.stop()

# --- Streamlit í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(layout="wide")

st.title("ğŸŒ ê±°ì‹œê²½ì œ ì§€í‘œ ê¸°ë°˜ ì‹œì¥ ì¶”ì„¸ ë¶„ì„")
st.markdown("FREDì™€ ECOS ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì‹œì¥ì˜ ê±°ì‹œê²½ì œ êµ­ë©´ì„ ë¶„ì„í•˜ê³ , í•œêµ­ ì£¼ì‹ ì‹œì¥ì˜ ì¶”ì„¸ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# --- ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ ---

@st.cache_data(ttl=3600 * 24 * 7) # 1ì£¼ì¼ ìºì‹œ ìœ ì§€
def get_fred_data(api_key):
    """FREDì—ì„œ ì£¼ìš” ê±°ì‹œê²½ì œ ì§€í‘œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. GDPëŠ” ì œì™¸ë©ë‹ˆë‹¤."""
    st.info("ğŸ”„ FRED ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    start_date = datetime(2010, 1, 1) # ì¶©ë¶„í•œ ê³¼ê±° ë°ì´í„°
    end_date = datetime.now()

    fred_codes = {
        'US_CPI_YoY': 'CPIAUCSL', # ë¯¸êµ­ CPI, ì›”ë³„ (ì „ë…„ ë™ê¸° ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°)
        'US_FFR': 'FEDFUNDS', # ë¯¸êµ­ ê¸°ì¤€ê¸ˆë¦¬, ì›”ë³„
        'US_10Y_Treasury': 'DGS10', # ë¯¸êµ­ 10ë…„ êµ­ì±„ê¸ˆë¦¬, ì¼ë³„ (ì›”ë§ ê°’ ì‚¬ìš©)
        'KRW_USD_ExcRate': 'DEXKOUS' # ì›/ë‹¬ëŸ¬ í™˜ìœ¨, ì¼ë³„ (ì›”ë§ ê°’ ì‚¬ìš©)
    }

    df_fred = pd.DataFrame()
    max_fred_retries = 3
    initial_fred_delay = 1 # ì´ˆ

    for name, code in fred_codes.items():
        for attempt in range(max_fred_retries):
            try:
                temp_df = web.DataReader(code, 'fred', start_date, end_date, api_key=api_key)
                df_fred = pd.concat([df_fred, temp_df], axis=1)
                st.info(f"âœ… FRED ë°ì´í„° ë¡œë“œ ì„±ê³µ: {name}")
                break # ì„±ê³µí•˜ë©´ ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ
            except Exception as e:
                if attempt < max_fred_retries - 1:
                    sleep_time = initial_fred_delay * (2 ** attempt) + random.uniform(0, 1)
                    st.warning(f"FRED ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜ ({name}, {code}): {e}. {sleep_time:.2f}ì´ˆ í›„ ì¬ì‹œë„... ({attempt + 1}/{max_fred_retries})")
                    time.sleep(sleep_time)
                else:
                    st.error(f"âŒ FRED ë°ì´í„° ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {name}, {code}. ì˜¤ë¥˜: {e}")
                    # ìµœì¢… ì‹¤íŒ¨ ì‹œ í•´ë‹¹ ì»¬ëŸ¼ì€ NaNìœ¼ë¡œ ë‚¨ì„ ìˆ˜ ìˆìŒ
                    
        time.sleep(random.uniform(0.3, 0.8)) # ê° ì§€í‘œ í˜¸ì¶œ í›„ ë¬´ì‘ìœ„ ì§€ì—°
    
    df_fred.columns = fred_codes.keys()
    df_fred = df_fred.resample('ME').last().ffill() # ëª¨ë“  ì§€í‘œë¥¼ ì›”ë§ ê¸°ì¤€ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§í•˜ê³ , ê²°ì¸¡ì¹˜ëŠ” ì´ì „ ê°’ìœ¼ë¡œ ì±„ì›€
    st.success("âœ… FRED ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    return df_fred

@st.cache_data(ttl=3600 * 24 * 7) # 1ì£¼ì¼ ìºì‹œ ìœ ì§€
def get_ecos_data(api_key):
    """ECOSì—ì„œ ì£¼ìš” í•œêµ­ ê±°ì‹œê²½ì œ ì§€í‘œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. GDPëŠ” í¬í•¨ë˜ì§€ ì•Šìœ¼ë©° ì‹¤ì—…ë¥ ì´ ì¶”ê°€ë©ë‹ˆë‹¤."""
    st.info("ğŸ”„ ECOS ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    base_url = "http://ecos.bok.or.kr/api/StatisticSearch/"
    
    # ECOS ì£¼ìš” ì§€í‘œ ì½”ë“œ ë° ì£¼ê¸° ì •ë³´
    ecos_codes_info = {
        'KR_CPI_YoY': {'code': '901Y009/0', 'freq': 'M', 'name_for_url': 'KPIC'}, # ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜ (ì´ì§€ìˆ˜)
        'KR_BaseRate': {'code': '722Y001/0101000', 'freq': 'M', 'name_for_url': 'KR_BaseRate'}, # ê¸°ì¤€ê¸ˆë¦¬
        'KR_Unemployment_Rate': {'code': '901Y027/I61BB', 'freq': 'M', 'name_for_url': 'KR_Unemployment_Rate'} # ì‹¤ì—…ë¥ 
    }

    df_ecos = pd.DataFrame()
    
    now = datetime.now()
    start_date_str_month = datetime(2010, 1, 1).strftime('%Y%m') 
    end_date_str_month = (now + timedelta(days=30)).strftime('%Y%m')

    max_ecos_retries = 3
    initial_ecos_delay = 1 # ì´ˆ

    for name, info in ecos_codes_info.items():
        stat_code, item_code = info['code'].split('/')
        freq = info['freq']
        
        current_start_date_str = start_date_str_month
        current_end_date_str = end_date_str_month

        url = f"{base_url}{api_key}/json/kr/1/1000/{stat_code}/{freq}/{current_start_date_str}/{current_end_date_str}/{item_code}"
        
        for attempt in range(max_ecos_retries):
            try:
                response = requests.get(url, timeout=10) # íƒ€ì„ì•„ì›ƒ 10ì´ˆ ì„¤ì •
                data = response.json()
                
                if 'StatisticSearch' in data and 'row' in data['StatisticSearch']:
                    rows = data['StatisticSearch']['row']
                    temp_df = pd.DataFrame(rows)
                    
                    if 'TIME' in temp_df.columns and 'DATA_VALUE' in temp_df.columns:
                        if freq == 'M':
                            temp_df['TIME'] = pd.to_datetime(temp_df['TIME'], format='%Y%m', errors='coerce') + pd.offsets.MonthEnd(0)
                        elif freq == 'D':
                            temp_df['TIME'] = pd.to_datetime(temp_df['TIME'], format='%Y%m%d', errors='coerce')
                        elif freq == 'A':
                            temp_df['TIME'] = pd.to_datetime(temp_df['TIME'], format='%Y', errors='coerce') + pd.offsets.YearEnd(0)
                        
                        temp_df.dropna(subset=['TIME'], inplace=True)
                        temp_df.drop_duplicates(subset=['TIME'], inplace=True)
                        temp_df.set_index('TIME', inplace=True)
                        
                        temp_df[name] = pd.to_numeric(temp_df['DATA_VALUE'], errors='coerce')
                        
                        if df_ecos.empty:
                            df_ecos = temp_df[[name]]
                        else:
                            df_ecos = pd.merge(df_ecos, temp_df[[name]], left_index=True, right_index=True, how='outer')
                        
                        st.info(f"âœ… ECOS ë°ì´í„° ë¡œë“œ ì„±ê³µ: {name}")
                        break # ì„±ê³µí•˜ë©´ ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ
                    else:
                        st.warning(f"ECOS ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: '{name}'ì— ì˜ˆìƒ ì»¬ëŸ¼ ì—†ìŒ. ì¬ì‹œë„... ({attempt + 1}/{max_ecos_retries})")
                        if attempt == max_ecos_retries - 1:
                            st.error(f"âŒ ECOS ë°ì´í„° ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {name}. ì˜ˆìƒ ì»¬ëŸ¼ ì—†ìŒ.")
                        time.sleep(initial_ecos_delay * (2 ** attempt) + random.uniform(0, 1))
                elif 'RESULT' in data and data['RESULT']['CODE'] != 'INFO-000':
                        st.warning(f"ECOS API í˜¸ì¶œ ì˜¤ë¥˜ ({name}, {info['code']}): {data['RESULT']['CODE']} - {data['RESULT']['MESSAGE']}. ì¬ì‹œë„... ({attempt + 1}/{max_ecos_retries})")
                        if attempt == max_ecos_retries - 1:
                            st.error(f"âŒ ECOS ë°ì´í„° ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {name}. API ì˜¤ë¥˜: {data['RESULT']['CODE']}")
                        time.sleep(initial_ecos_delay * (2 ** attempt) + random.uniform(0, 1))
                else:
                    st.warning(f"ECOS ë°ì´í„° ì˜¤ë¥˜ ë˜ëŠ” ì‘ë‹µ ì—†ìŒ: {name}. ì¬ì‹œë„... ({attempt + 1}/{max_ecos_retries})")
                    if attempt == max_ecos_retries - 1:
                        st.error(f"âŒ ECOS ë°ì´í„° ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {name}. ì‘ë‹µ ì—†ìŒ.")
                    time.sleep(initial_ecos_delay * (2 ** attempt) + random.uniform(0, 1))
                    
            except requests.exceptions.Timeout:
                st.warning(f"ECOS API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ ({name}, {info['code']}). ì¬ì‹œë„... ({attempt + 1}/{max_ecos_retries})")
                if attempt == max_ecos_retries - 1:
                    st.error(f"âŒ ECOS ë°ì´í„° ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {name}. íƒ€ì„ì•„ì›ƒ.")
                time.sleep(initial_ecos_delay * (2 ** attempt) + random.uniform(0, 1))
            except requests.exceptions.JSONDecodeError as e:
                # JSON ë””ì½”ë”© ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‘ë‹µ ë‚´ìš© í™•ì¸
                st.warning(f"ECOS ì‘ë‹µ JSON ë””ì½”ë”© ì˜¤ë¥˜ ({name}, {info['code']}): {e}")
                st.warning(f"ìˆ˜ì‹ ëœ ì‘ë‹µì˜ ìƒíƒœ ì½”ë“œ: {response.status_code if 'response' in locals() else 'N/A'}")
                st.warning(f"ìˆ˜ì‹ ëœ ì‘ë‹µ ë‚´ìš© (ë””ì½”ë”© ì‹¤íŒ¨): {response.text[:500] if 'response' in locals() else 'N/A'}")
                if attempt < max_ecos_retries - 1:
                    sleep_time = initial_ecos_delay * (2 ** attempt) + random.uniform(0, 1)
                    st.info(f"{sleep_time:.2f}ì´ˆ í›„ ì¬ì‹œë„... ({attempt + 1}/{max_ecos_retries})")
                    time.sleep(sleep_time)
                else:
                    st.error(f"âŒ ECOS ë°ì´í„° ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {name}. JSON ë””ì½”ë”© ì˜¤ë¥˜.")
            except Exception as e:
                st.warning(f"ECOS ë°ì´í„° ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ({name}, {info['code']}): {e}. ì¬ì‹œë„... ({attempt + 1}/{max_ecos_retries})")
                if attempt == max_ecos_retries - 1:
                    st.error(f"âŒ ECOS ë°ì´í„° ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {name}. ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜.")
                time.sleep(initial_ecos_delay * (2 ** attempt) + random.uniform(0, 1))
        
        time.sleep(random.uniform(0.3, 0.8)) # ê° ì§€í‘œ í˜¸ì¶œ í›„ ë¬´ì‘ìœ„ ì§€ì—°
    
    if not df_ecos.empty:
        df_ecos = df_ecos.resample('ME').last().ffill() # ì›”ë§ ê¸°ì¤€ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§
    else:
        st.error("ECOSì—ì„œ ìœ íš¨í•œ ë°ì´í„°ë¥¼ ì „í˜€ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ECOS API í‚¤, í†µê³„í‘œ ì½”ë“œ ë° ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
    st.success("âœ… ECOS ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    return df_ecos

@st.cache_data(ttl=3600 * 24 * 7) # 1ì£¼ì¼ ìºì‹œ ìœ ì§€
def get_stock_data():
    """KOSPI ì§€ìˆ˜ ë° S&P 500 ETF (SPY) ë°ì´í„°ë¥¼ FinanceDataReaderë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    st.info("ğŸ”„ ì£¼ì‹ ì§€ìˆ˜ ë°ì´í„° (KOSPI, S&P 500) ìˆ˜ì§‘ ì¤‘...")
    start_date = datetime(2010, 1, 1)
    end_date = datetime.now()
    
    df_stocks = pd.DataFrame()

    max_stock_retries = 5 # ì£¼ì‹ ë°ì´í„°ëŠ” íŠ¹íˆ ë” ë§ì€ ì¬ì‹œë„ë¥¼ ì„¤ì • (KRXê°€ ê¹Œë‹¤ë¡œìš¸ ìˆ˜ ìˆìŒ)
    initial_stock_delay = 2 # ì´ˆ (KRXëŠ” ì¢€ ë” ê¸´ ì§€ì—°ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ)

    # KOSPI ë°ì´í„° ë¡œë“œ
    for attempt in range(max_stock_retries):
        try:
            df_kospi = fdr.DataReader('KS11', start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'))
            
            if 'Close' in df_kospi.columns:
                df_kospi_monthly = df_kospi['Close'].resample('ME').last().ffill().to_frame(name='KOSPI_Close')
                df_stocks = pd.concat([df_stocks, df_kospi_monthly], axis=1)
                st.success("âœ… KOSPI ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
                break # ì„±ê³µí•˜ë©´ ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ
            else:
                st.warning("KOSPI ë°ì´í„°ì— 'Close' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì¬ì‹œë„... (FinanceDataReader ì»¬ëŸ¼ ë¬¸ì œì¼ ìˆ˜ ìˆìŒ)")
                if attempt < max_stock_retries - 1:
                    sleep_time = initial_stock_delay * (2 ** attempt) + random.uniform(0, 2) # ë” ê¸´ ëœë¤ ì§€ì—°
                    st.info(f"{sleep_time:.2f}ì´ˆ í›„ ì¬ì‹œë„... ({attempt + 1}/{max_stock_retries})")
                    time.sleep(sleep_time)
                else:
                    st.error("âŒ KOSPI ë°ì´í„° ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: 'Close' ì»¬ëŸ¼ ì—†ìŒ.")

        except Exception as e:
            if attempt < max_stock_retries - 1:
                sleep_time = initial_stock_delay * (2 ** attempt) + random.uniform(0, 2) # ë” ê¸´ ëœë¤ ì§€ì—°
                st.warning(f"âŒ KOSPI ì§€ìˆ˜ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. {sleep_time:.2f}ì´ˆ í›„ ì¬ì‹œë„... ({attempt + 1}/{max_stock_retries})")
                time.sleep(sleep_time)
            else:
                st.error(f"âŒ KOSPI ì§€ìˆ˜ ë°ì´í„° ë¡œë“œ ìµœì¢… ì˜¤ë¥˜ ë°œìƒ: {e}. FinanceDataReader ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                # ìµœì¢… ì‹¤íŒ¨í•˜ë”ë¼ë„ SPY ë°ì´í„°ëŠ” ì‹œë„í•  ìˆ˜ ìˆë„ë¡ ì²˜ë¦¬

    time.sleep(random.uniform(0.5, 1.5)) # KOSPI ë¡œë“œ í›„ SPY ë¡œë“œ ì „ ì§€ì—°

    # S&P 500 ETF (SPY) ë°ì´í„° ë¡œë“œ
    for attempt in range(max_stock_retries): # SPYë„ ì¬ì‹œë„ ë¡œì§ ì ìš©
        try:
            df_spy = fdr.DataReader('SPY', start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'))
            if 'Close' in df_spy.columns:
                df_spy_monthly = df_spy['Close'].resample('ME').last().ffill().to_frame(name='US_Stock_Close')
                df_stocks = pd.concat([df_stocks, df_spy_monthly], axis=1)
                st.success("âœ… S&P 500 ETF (SPY) ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
                break # ì„±ê³µí•˜ë©´ ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ
            else:
                st.warning("S&P 500 ë°ì´í„°ì— 'Close' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì¬ì‹œë„... (FinanceDataReader ì»¬ëŸ¼ ë¬¸ì œì¼ ìˆ˜ ìˆìŒ)")
                if attempt < max_stock_retries - 1:
                    sleep_time = initial_stock_delay * (2 ** attempt) + random.uniform(0, 2)
                    st.info(f"{sleep_time:.2f}ì´ˆ í›„ ì¬ì‹œë„... ({attempt + 1}/{max_stock_retries})")
                    time.sleep(sleep_time)
                else:
                    st.error("âŒ S&P 500 ETF (SPY) ë°ì´í„° ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: 'Close' ì»¬ëŸ¼ ì—†ìŒ.")
        except Exception as e:
            if attempt < max_stock_retries - 1:
                sleep_time = initial_stock_delay * (2 ** attempt) + random.uniform(0, 2)
                st.warning(f"âŒ S&P 500 ETF (SPY) ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. {sleep_time:.2f}ì´ˆ í›„ ì¬ì‹œë„... ({attempt + 1}/{max_stock_retries})")
                time.sleep(sleep_time)
            else:
                st.error(f"âŒ S&P 500 ETF (SPY) ë°ì´í„° ë¡œë“œ ìµœì¢… ì˜¤ë¥˜ ë°œìƒ: {e}. FinanceDataReader ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    if df_stocks.empty:
        st.error("ì£¼ì‹ ì§€ìˆ˜ ë°ì´í„°ë¥¼ ì „í˜€ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    return df_stocks


# --- ë°ì´í„° ì „ì²˜ë¦¬ ë° íŒŒìƒ ë³€ìˆ˜ ìƒì„± ---
@st.cache_data
def preprocess_and_engineer_features(df_fred, df_ecos, df_stocks):
    st.info("ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ë° íŒ©í„° ìƒì„± ì¤‘...")
    
    valid_dfs = [df for df in [df_fred, df_ecos, df_stocks] if not df.empty]
    
    if not valid_dfs:
        st.error("ëª¨ë“  ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆì–´ ë°ì´í„°ë¥¼ ë³‘í•©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(), []

    # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ì˜ ì¸ë±ìŠ¤(ë‚ ì§œ)ë¥¼ ê°€ì ¸ì™€ì„œ ê°€ì¥ ì´ë¥¸ ì‹œì‘ ë‚ ì§œì™€ ê°€ì¥ ëŠ¦ì€ ì¢…ë£Œ ë‚ ì§œë¥¼ ì°¾ìŒ
    all_indices = [df.index for df in valid_dfs]
    min_date = min(idx.min() for idx in all_indices)
    max_date = max(idx.max() for idx in all_indices)

    # ì „ì²´ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ì›”ë§ ë‚ ì§œ ë²”ìœ„ ìƒì„±
    full_month_range = pd.date_range(start=min_date, end=max_date, freq='ME')
    
    df_merged = pd.DataFrame(index=full_month_range)
    
    if not df_fred.empty:
        df_merged = pd.merge(df_merged, df_fred, left_index=True, right_index=True, how='left')
    if not df_ecos.empty:
        df_merged = pd.merge(df_merged, df_ecos, left_index=True, right_index=True, how='left')
    if not df_stocks.empty:
        df_merged = pd.merge(df_merged, df_stocks, left_index=True, right_index=True, how='left')

    df_merged.ffill(inplace=True)
    df_merged.bfill(inplace=True)

    # ì£¼ìš” íŒ©í„° ìƒì„±
    if 'US_CPI_YoY' in df_merged.columns:
        df_merged['US_CPI_YoY_Change'] = df_merged['US_CPI_YoY'].pct_change(12) * 100
    else: df_merged['US_CPI_YoY_Change'] = np.nan

    if 'KR_CPI_YoY' in df_merged.columns:
        df_merged['KR_CPI_YoY_Change'] = df_merged['KR_CPI_YoY'].pct_change(12) * 100
    else: df_merged['KR_CPI_YoY_Change'] = np.nan

    if 'KR_Unemployment_Rate' in df_merged.columns:
        df_merged['KR_Unemployment_Rate_YoY_Change'] = df_merged['KR_Unemployment_Rate'].diff(12) # ì „ë…„ ë™ì›” ëŒ€ë¹„ ë³€í™” (ì ˆëŒ€ê°’)
    else: df_merged['KR_Unemployment_Rate_YoY_Change'] = np.nan

    if 'US_FFR' in df_merged.columns:
        df_merged['US_FFR_Change'] = df_merged['US_FFR'].diff()
    else: df_merged['US_FFR_Change'] = np.nan

    if 'KR_BaseRate' in df_merged.columns:
        df_merged['KR_BaseRate_Change'] = df_merged['KR_BaseRate'].diff()
    else: df_merged['KR_BaseRate_Change'] = np.nan

    if 'KRW_USD_ExcRate' in df_merged.columns:
        df_merged['KRW_USD_ExcRate_Change'] = df_merged['KRW_USD_ExcRate'].pct_change(1) * 100
    else: df_merged['KRW_USD_ExcRate_Change'] = np.nan

    if 'US_10Y_Treasury' in df_merged.columns:
        df_merged['US_10Y_Treasury_Change'] = df_merged['US_10Y_Treasury'].diff()
    else:
        df_merged['US_10Y_Treasury_Change'] = np.nan

    # KOSPI ë‹¤ìŒ ë‹¬ ìˆ˜ìµë¥ 
    if 'KOSPI_Close' in df_merged.columns:
        df_merged['KOSPI_Next_Month_Return'] = df_merged['KOSPI_Close'].pct_change(1).shift(-1) * 100
    else: df_merged['KOSPI_Next_Month_Return'] = np.nan

    # ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ (S&P 500) ë‹¤ìŒ ë‹¬ ìˆ˜ìµë¥ 
    if 'US_Stock_Close' in df_merged.columns:
        df_merged['US_Next_Month_Return'] = df_merged['US_Stock_Close'].pct_change(1).shift(-1) * 100
    else: df_merged['US_Next_Month_Return'] = np.nan


    features = [
        'US_CPI_YoY_Change', 
        'KR_CPI_YoY_Change', 
        'KR_Unemployment_Rate_YoY_Change',
        'US_FFR', 'US_FFR_Change', 'KR_BaseRate', 'KR_BaseRate_Change',
        'KRW_USD_ExcRate_Change',
        'US_10Y_Treasury', 'US_10Y_Treasury_Change'
    ]
    
    actual_features = [f for f in features if f in df_merged.columns]

    # KOSPIì™€ ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ì˜ ë‹¤ìŒ ë‹¬ ìˆ˜ìµë¥ ë„ ìµœì¢… ë°ì´í„°ì— í¬í•¨
    target_returns = ['KOSPI_Next_Month_Return', 'US_Next_Month_Return']
    actual_targets = [t for t in target_returns if t in df_merged.columns]

    df_final = df_merged[actual_features + actual_targets].dropna()

    st.success("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ë° íŒ©í„° ìƒì„± ì™„ë£Œ!")
    return df_final, actual_features, actual_targets

# --- ì‹œì¥ êµ­ë©´ ì •ì˜ ë° ì˜ˆì¸¡ ëª¨ë¸ ---
@st.cache_data
def define_market_regime(df):
    st.info("ğŸ”„ ì‹œì¥ êµ­ë©´ ì •ì˜ ì¤‘...")
    df_regime = df.copy()

    df_regime['Growth_Trend'] = True # ì´ ê°’ì€ í˜„ì¬ ì‹œì¥ êµ­ë©´ ë¶„ë¥˜ ë¡œì§ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

    # CPI ì§€í‘œ(ë¯¸êµ­, í•œêµ­) ëª¨ë‘ ì‚¬ìš©
    if 'US_CPI_YoY_Change' in df_regime.columns and 'KR_CPI_YoY_Change' in df_regime.columns:
        df_regime['Inflation_Trend'] = (df_regime['US_CPI_YoY_Change'].rolling(window=6).mean() > 0) & \
                                         (df_regime['KR_CPI_YoY_Change'].rolling(window=6).mean() > 0)
    elif 'US_CPI_YoY_Change' in df_regime.columns: # í•œêµ­ CPIê°€ ì—†ì„ ê²½ìš° ë¯¸êµ­ CPIë§Œ ì‚¬ìš©
        df_regime['Inflation_Trend'] = (df_regime['US_CPI_YoY_Change'].rolling(window=6).mean() > 0)
    else:
        df_regime['Inflation_Trend'] = False

    def classify_regime(row):
        # GDPê°€ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ, ì‹œì¥ êµ­ë©´ì€ ë¬¼ê°€ ì¶”ì„¸ì—ë§Œ ì˜ì¡´í•˜ì—¬ ë¶„ë¥˜í•©ë‹ˆë‹¤.
        if row['Inflation_Trend']:
            return "ë¬¼ê°€ ìƒìŠ¹ êµ­ë©´ (Inflationary Period)"
        else:
            return "ë¬¼ê°€ í•˜ë½ êµ­ë©´ (Disinflationary Period)"

    df_regime['Market_Regime'] = df_regime.apply(classify_regime, axis=1)
    
    st.success("âœ… ì‹œì¥ êµ­ë©´ ì •ì˜ ì™„ë£Œ!")
    return df_regime

# --- Streamlit UI ë° ì‹¤í–‰ ë¡œì§ ---

st.markdown("---")
st.subheader("ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì‹œì‘")
st.write("ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ FRED, ECOS, KOSPI ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì‹œì¥ êµ­ë©´ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")

if st.button("ğŸš€ **ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì‹œì‘!**", key="start_analysis_button"):
    with st.spinner("ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”..."):
        # 1. ë°ì´í„° ìˆ˜ì§‘
        df_fred = get_fred_data(FRED_API_KEY)
        df_ecos = get_ecos_data(ECOS_API_KEY) # CPI, ê¸°ì¤€ê¸ˆë¦¬, ì‹¤ì—…ë¥  í¬í•¨ëœ ECOS ë°ì´í„° í˜¸ì¶œ
        df_stocks = get_stock_data() # KOSPI ë° SPY ë°ì´í„° í˜¸ì¶œ

        # ë°ì´í„°ê°€ í•˜ë‚˜ë¼ë„ ë¹„ì–´ìˆìœ¼ë©´ ê²½ê³  í›„ ì¤‘ë‹¨
        if df_fred.empty or df_ecos.empty or df_stocks.empty:
            st.error("âš ï¸ í•„ìˆ˜ ë°ì´í„°(FRED, ECOS, ì£¼ì‹ ì§€ìˆ˜) ì¤‘ ì¼ë¶€ ë˜ëŠ” ì „ë¶€ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ ê²½ê³  ë©”ì‹œì§€(API í‚¤, ì¸í„°ë„· ì—°ê²° ë“±)ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            st.stop()
        
        # 2. ë°ì´í„° ì „ì²˜ë¦¬ ë° íŒ©í„° ìƒì„±
        df_final, features, targets = preprocess_and_engineer_features(df_fred, df_ecos, df_stocks)

        if df_final.empty:
            st.error("ë°ì´í„° ì „ì²˜ë¦¬ í›„ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ì˜ ë‚ ì§œ ë²”ìœ„ ë˜ëŠ” ê²°ì¸¡ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            st.stop()

        # 3. ì‹œì¥ êµ­ë©´ ì •ì˜
        df_regime_classified = define_market_regime(df_final)

        st.subheader("ğŸ“š **ë¶„ì„ëœ ê±°ì‹œê²½ì œ ì§€í‘œ ë° ì‹œì¥ êµ­ë©´**")
        st.dataframe(df_regime_classified.tail(15))

        latest_regime = df_regime_classified['Market_Regime'].iloc[-1]
        st.markdown(f"### â¡ï¸ í˜„ì¬ ì‹œì¥ êµ­ë©´: **{latest_regime}**")
        
        st.subheader("ğŸ“ˆ **ì‹œì¥ êµ­ë©´ë³„ ì£¼ì‹ ì‹œì¥ ì›”ë³„ í‰ê·  ìˆ˜ìµë¥  ë¶„ì„**")
        
        col1, col2 = st.columns(2)

        # KOSPI êµ­ë©´ë³„ ìˆ˜ìµë¥ 
        with col1:
            if 'KOSPI_Next_Month_Return' in df_regime_classified.columns:
                kospi_regime_performance = df_regime_classified.groupby('Market_Regime')['KOSPI_Next_Month_Return'].agg(['count', 'mean', 'std']).sort_values('mean', ascending=False)
                
                fig_kospi_regime, ax_kospi_regime = plt.subplots(figsize=(10, 6))
                sns.barplot(x=kospi_regime_performance.index, y=kospi_regime_performance['mean'], ax=ax_kospi_regime, palette='viridis')
                ax_kospi_regime.set_title("KOSPI ì‹œì¥ êµ­ë©´ë³„ ì›”ë³„ í‰ê·  ìˆ˜ìµë¥  (%)")
                ax_kospi_regime.set_xlabel("ì‹œì¥ êµ­ë©´")
                ax_kospi_regime.set_ylabel("í‰ê·  ì›”ë³„ ìˆ˜ìµë¥  (%)")
                ax_kospi_regime.tick_params(axis='x', rotation=45)
                plt.tight_layout()
                st.pyplot(fig_kospi_regime)
                st.write("---")
                st.write("**KOSPI êµ­ë©´ë³„ ìˆ˜ìµë¥  í†µê³„:**")
                st.dataframe(kospi_regime_performance)
            else:
                st.warning("KOSPI ì‹œì¥ êµ­ë©´ë³„ ìˆ˜ìµë¥  ë°ì´í„°ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ (S&P 500) êµ­ë©´ë³„ ìˆ˜ìµë¥ 
        with col2:
            if 'US_Next_Month_Return' in df_regime_classified.columns:
                us_regime_performance = df_regime_classified.groupby('Market_Regime')['US_Next_Month_Return'].agg(['count', 'mean', 'std']).sort_values('mean', ascending=False)
                
                fig_us_regime, ax_us_regime = plt.subplots(figsize=(10, 6))
                sns.barplot(x=us_regime_performance.index, y=us_regime_performance['mean'], ax=ax_us_regime, palette='plasma')
                ax_us_regime.set_title("S&P 500 ì‹œì¥ êµ­ë©´ë³„ ì›”ë³„ í‰ê·  ìˆ˜ìµë¥  (%)")
                ax_us_regime.set_xlabel("ì‹œì¥ êµ­ë©´")
                ax_us_regime.set_ylabel("í‰ê·  ì›”ë³„ ìˆ˜ìµë¥  (%)")
                ax_us_regime.tick_params(axis='x', rotation=45)
                plt.tight_layout()
                st.pyplot(fig_us_regime)
                st.write("---")
                st.write("**S&P 500 êµ­ë©´ë³„ ìˆ˜ìµë¥  í†µê³„:**")
                st.dataframe(us_regime_performance)
            else:
                st.warning("S&P 500 ì‹œì¥ êµ­ë©´ë³„ ìˆ˜ìµë¥  ë°ì´í„°ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


        st.markdown("---")
        st.subheader("ğŸ“Š **ì£¼ìš” ê±°ì‹œê²½ì œ ì§€í‘œ ì¶”ì„¸ (ìµœê·¼ 5ë…„)**")
        
        plot_df = df_regime_classified.last('5Y')
        
        cols = st.columns(3)
        for i, feature in enumerate(features):
            with cols[i % 3]:
                if feature in plot_df.columns:
                    fig, ax = plt.subplots(figsize=(8, 4))
                    ax.plot(plot_df.index, plot_df[feature])
                    ax.set_title(feature)
                    ax.grid(True)
                    plt.tight_layout()
                    st.pyplot(fig)
                else:
                    st.write(f"âš ï¸ **'{feature}'** ì§€í‘œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì‹œê°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        st.markdown("---")
        st.subheader("Correlation Heatmap: Macroeconomic Factors vs. Stock Returns")
        st.write("ê±°ì‹œê²½ì œ ì§€í‘œ ë³€í™”ì™€ í•œêµ­/ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ì˜ ë‹¤ìŒ ë‹¬ ìˆ˜ìµë¥  ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.")

        corr_df = df_final[features + targets].corr()
        
        fig_corr, ax_corr = plt.subplots(figsize=(12, 8))
        sns.heatmap(corr_df.loc[features, targets], annot=True, cmap='coolwarm', fmt=".2f", ax=ax_corr)
        ax_corr.set_title("ê±°ì‹œê²½ì œ ì§€í‘œì™€ ì£¼ì‹ ì‹œì¥ ë‹¤ìŒ ë‹¬ ìˆ˜ìµë¥  ê°„ì˜ ìƒê´€ê´€ê³„")
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        st.pyplot(fig_corr)

        st.markdown("---")
        st.subheader("ğŸ”® **ì‹œì¥ ì¶”ì„¸ ë¶„ì„ ê²°ë¡  ë° ì œì•ˆ**")
        st.write(f"í˜„ì¬ ê±°ì‹œê²½ì œ ì§€í‘œë¥¼ ë¶„ì„í•œ ê²°ê³¼, ì‹œì¥ì€ **'{latest_regime}'** êµ­ë©´ì— ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.")
        
        # í˜„ì¬ êµ­ë©´ë³„ KOSPI ì˜ˆìƒ ìˆ˜ìµë¥ 
        if 'KOSPI_Next_Month_Return' in df_regime_classified.columns and latest_regime in kospi_regime_performance.index:
            kospi_expected_return = kospi_regime_performance.loc[latest_regime, 'mean']
            st.write(f"ê³¼ê±° ë°ì´í„°ì— ê¸°ë°˜í•  ë•Œ, í˜„ì¬ **'{latest_regime}'** êµ­ë©´ì—ì„œ KOSPIì˜ ì›” í‰ê·  ìˆ˜ìµë¥ ì€ **{kospi_expected_return:.2f}%**ì˜€ìŠµë‹ˆë‹¤.")
            if kospi_expected_return > 0:
                st.success("âœ… í˜„ì¬ êµ­ë©´ì€ KOSPIì— ê¸ì •ì ì¸ ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤.")
            else:
                st.warning("âš ï¸ í˜„ì¬ êµ­ë©´ì€ KOSPIì— ë¶€ì •ì ì¸ ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤. ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            st.warning("KOSPI ì‹œì¥ì˜ í˜„ì¬ êµ­ë©´ ì˜ˆìƒ ìˆ˜ìµë¥ ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # í˜„ì¬ êµ­ë©´ë³„ S&P 500 ì˜ˆìƒ ìˆ˜ìµë¥ 
        if 'US_Next_Month_Return' in df_regime_classified.columns and latest_regime in us_regime_performance.index:
            us_expected_return = us_regime_performance.loc[latest_regime, 'mean']
            st.write(f"ê³¼ê±° ë°ì´í„°ì— ê¸°ë°˜í•  ë•Œ, í˜„ì¬ **'{latest_regime}'** êµ­ë©´ì—ì„œ S&P 500ì˜ ì›” í‰ê·  ìˆ˜ìµë¥ ì€ **{us_expected_return:.2f}%**ì˜€ìŠµë‹ˆë‹¤.")
            if us_expected_return > 0:
                st.success("âœ… í˜„ì¬ êµ­ë©´ì€ S&P 500ì— ê¸ì •ì ì¸ ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤.")
            else:
                st.warning("âš ï¸ í˜„ì¬ êµ­ë©´ì€ S&P 500ì— ë¶€ì •ì ì¸ ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤. ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            st.warning("S&P 500 ì‹œì¥ì˜ í˜„ì¬ êµ­ë©´ ì˜ˆìƒ ìˆ˜ìµë¥ ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        st.markdown("ì´ ë¶„ì„ì€ ê³¼ê±° ë°ì´í„°ì— ê¸°ë°˜í•œ í†µê³„ì  ê²½í–¥ì„ ë³´ì—¬ì£¼ë©°, ë¯¸ë˜ ì„±ê³¼ë¥¼ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‹¤ì œ íˆ¬ì ê²°ì • ì‹œì—ëŠ” ì¶”ê°€ì ì¸ ë¶„ì„ê³¼ ì „ë¬¸ê°€ì˜ ì¡°ì–¸ì„ êµ¬í•˜ì‹­ì‹œì˜¤.")
