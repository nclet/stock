import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import os

# ê¸ˆìœµ ë°ì´í„° ë¡œë” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
try:
    import FinanceDataReader as fdr
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_squared_error, r2_score
    from sklearn.model_selection import train_test_split
except ImportError:
    st.error("""
    **í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!**
    ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:
    `pip install FinanceDataReader scikit-learn pandas matplotlib streamlit`
    """)
    st.stop()

# --- Streamlit í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(layout="wide")

st.title("ğŸš€ ì£¼ê°€ ìˆ˜ìµë¥  ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ (RandomForest with FinanceDataReader)")
st.markdown("`FinanceDataReader`ë¥¼ í†µí•´ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ê³¼ê±° ì£¼ê°€ ë°ì´í„°ì™€ ê¸°ìˆ ì  ì§€í‘œë¥¼ í™œìš©í•˜ì—¬ **ë‹¤ìŒ ê±°ë˜ì¼ì˜ ìˆ˜ìµë¥ **ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# --- ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ ---
@st.cache_data
def calculate_bollinger_bands_pred(prices, window=20, num_std=2):
    """ë³¼ë¦°ì € ë°´ë“œ (Bollinger Bands)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    rolling_mean = prices.rolling(window).mean()
    rolling_std = prices.rolling(window).std()
    upper_band = rolling_mean + (rolling_std * num_std)
    lower_band = rolling_mean - (rolling_std * num_std)
    return rolling_mean, upper_band, lower_band

@st.cache_data
def calculate_rsi_pred(series, period=14):
    """ìƒëŒ€ê°•ë„ì§€ìˆ˜ (RSI)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    delta = series.diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.rolling(window=period).mean()
    avg_loss = loss.rolling(window=period).mean()
    rs = avg_gain / avg_loss.replace(0, np.nan).fillna(0)
    rsi = 100 - (100 / (1 + rs))
    return rsi

# --- FinanceDataReaderë¥¼ ì´ìš©í•œ ì¢…ëª© ì •ë³´ ë° ì£¼ê°€ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ---

@st.cache_data # ì¢…ëª© ì½”ë“œ ì •ë³´ë¥¼ ìºì‹œí•˜ì—¬ ë¹ ë¥´ê²Œ ë¡œë“œ
def get_krx_stock_list():
    """KRX ìƒì¥ì‚¬ ì „ì²´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        df_krx = fdr.StockListing('KRX')
        # 'Code' ì»¬ëŸ¼ì´ ë¬¸ìì—´ì´ê³  6ìë¦¬ë¡œ ì±„ì›Œì ¸ ìˆëŠ”ì§€ í™•ì¸ (ì„ íƒ ì‚¬í•­)
        df_krx['Code'] = df_krx['Code'].astype(str).str.zfill(6)
        # ì¢…ëª©ëª…ê³¼ ì½”ë“œ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„± (ì˜ˆ: {'ì‚¼ì„±ì „ì': '005930', ...})
        name_code_dict = df_krx.set_index('Name')['Code'].to_dict()
        st.success("âœ… KRX ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return name_code_dict
    except Exception as e:
        st.error(f"âŒ KRX ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.info("ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ 'FinanceDataReader' ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì„ í™•ì¸í•´ë³´ì„¸ìš”.")
        return {}

@st.cache_data # ê°œë³„ ì¢…ëª© ì£¼ê°€ ë°ì´í„°ë¥¼ ìºì‹œí•˜ì—¬ ë¹ ë¥´ê²Œ ë¡œë“œ
def load_stock_data_from_fdr(stock_code, start_date=None, end_date=None):
    """FinanceDataReaderë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì¢…ëª©ì˜ ì£¼ê°€ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        # ê¸°ë³¸ì ìœ¼ë¡œ ì§€ë‚œ 5ë…„ê°„ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ì„¤ì • (RandomForest í›ˆë ¨ì— ì¶©ë¶„í•œ ë°ì´í„°)
        if end_date is None:
            end_date = datetime.now()
        if start_date is None:
            start_date = end_date - timedelta(days=5*365) # ëŒ€ëµ 5ë…„ì¹˜ ë°ì´í„°

        df = fdr.DataReader(stock_code, start=start_date, end=end_date)
        
        if df.empty:
            st.warning(f"'{stock_code}'ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¢…ëª© ì½”ë“œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()
        
        # ì»¬ëŸ¼ëª… í†µì¼ (FinanceDataReaderëŠ” 'Close' ëŒ€ì‹  'Close'ë¥¼ ì‚¬ìš©)
        if 'Close' not in df.columns:
            st.error(f"'{stock_code}' ë°ì´í„°ì— 'Close' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        df.sort_index(inplace=True) # ë‚ ì§œ ìˆœ ì •ë ¬
        st.success(f"âœ… '{stock_code}' ì£¼ê°€ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. (ì´ {len(df)}ê°œ ë°ì´í„° í¬ì¸íŠ¸)")
        return df
    except Exception as e:
        st.error(f"'{stock_code}' ì£¼ê°€ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# --- Streamlit UI ì‹œì‘ ---
# ëª¨ë“  ì¢…ëª© ì½”ë“œ ë¡œë“œ (ì²« ë¡œë“œ ì‹œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŒ)
name_code_dict = get_krx_stock_list()

if not name_code_dict:
    st.info("KRX ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•±ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    st.stop()

# ì¢…ëª© ì„ íƒ
selected_name = st.selectbox("ğŸ”® **ì˜ˆì¸¡í•  ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”**", sorted(name_code_dict.keys()))
selected_code = name_code_dict[selected_name]

if st.button("ğŸš€ **ì˜ˆì¸¡ ì‹œì‘!**"):
    with st.spinner("ë°ì´í„° ë¡œë“œ ë° RandomForest ëª¨ë¸ ì˜ˆì¸¡ ì¤‘..."):
        # FinanceDataReaderë¥¼ í†µí•´ ì„ íƒëœ ì¢…ëª©ì˜ ì£¼ê°€ ë°ì´í„° ë¡œë“œ
        df_stock = load_stock_data_from_fdr(selected_code)

        if df_stock.empty:
            st.stop()

        # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        df_stock['RSI'] = calculate_rsi_pred(df_stock['Close'])
        df_stock['BB_Mid'], df_stock['BB_Upper'], df_stock['BB_Lower'] = calculate_bollinger_bands_pred(df_stock['Close'])

        # RandomForest ëª¨ë¸ì— ì‚¬ìš©í•  Featuresì™€ Target ì •ì˜
        ml_features = ['Close', 'RSI', 'BB_Upper', 'BB_Lower']
        
        # ë‹¤ìŒ ë‚  ìˆ˜ìµë¥  ê³„ì‚° (RandomForestì˜ ì˜ˆì¸¡ ëª©í‘œ)
        df_stock['Next_Day_Return'] = df_stock['Close'].pct_change().shift(-1) * 100
        
        # ê²°ì¸¡ì¹˜ ì œê±°
        df_ml = df_stock[ml_features + ['Next_Day_Return']].dropna()

        if len(df_ml) < 20: 
            st.warning(f"[RandomForest] ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ìˆ˜ìµë¥  ì˜ˆì¸¡ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 20ì¼ ì´ìƒì˜ ìœ íš¨í•œ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬ {len(df_ml)}ì¼)")
            st.stop()
        
        X_ml = df_ml[ml_features].values
        y_ml = df_ml['Next_Day_Return'].values

        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (íŠ¹ì„± ìŠ¤ì¼€ì¼ë§)
        scaler_ml = MinMaxScaler()
        X_ml_scaled = scaler_ml.fit_transform(X_ml)

        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¶„ë¦¬ (ë§ˆì§€ë§‰ 20%ë¥¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ìš©)
        test_size_ml = max(1, int(0.2 * len(X_ml_scaled))) 
        X_train_ml, X_test_ml = X_ml_scaled[:-test_size_ml], X_ml_scaled[-test_size_ml:]
        y_train_ml, y_test_ml = y_ml[:-test_size_ml], y_ml[-test_size_ml:]
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì´ ë„ˆë¬´ ì‘ì„ ê²½ìš° ì²˜ë¦¬
        if len(X_test_ml) == 0:
            st.warning(f"[RandomForest] í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ëª¨ë¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì‹  í•™ìŠµ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ìƒ˜í”Œë¡œ í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.")
            X_test_ml = X_train_ml[-1:] # í•™ìŠµ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ìƒ˜í”Œì„ í…ŒìŠ¤íŠ¸ë¡œ ì‚¬ìš©
            y_test_ml = y_train_ml[-1:] 
        
        st.info("RandomForest ëª¨ë¸ í•™ìŠµ ì¤‘...")
        # RandomForestRegressor ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ
        rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1) # n_jobs=-1ë¡œ ëª¨ë“  ì½”ì–´ ì‚¬ìš©
        with st.spinner("ğŸ”„ RandomForest ëª¨ë¸ í•™ìŠµ ì¤‘..."):
            rf_model.fit(X_train_ml, y_train_ml)
        st.success("âœ… RandomForest ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

        # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        y_pred_ml = rf_model.predict(X_test_ml)
        
        st.subheader("ğŸ“Š **RandomForest ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„°)**")
        st.write(f"**í‰ê·  ì œê³± ì˜¤ì°¨ (MSE)**: {mean_squared_error(y_test_ml, y_pred_ml):.2f}")
        st.write(f"**ê²°ì • ê³„ìˆ˜ (RÂ² Score)**: {r2_score(y_test_ml, y_pred_ml):.2f}")
        st.write(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ **í‰ê·  ì‹¤ì œ ìˆ˜ìµë¥ **: {np.mean(y_test_ml):.2f}%")
        st.write(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ **í‰ê·  ì˜ˆì¸¡ ìˆ˜ìµë¥ **: {np.mean(y_pred_ml):.2f}%")

        # ë‹¤ìŒ ê±°ë˜ì¼ ìˆ˜ìµë¥  ì˜ˆì¸¡
        last_data_ml = X_ml_scaled[-1].reshape(1, -1)
        next_day_return_pred_ml = rf_model.predict(last_data_ml)[0]

        st.subheader("ğŸ“ˆ **RandomForest ë‹¤ìŒ ê±°ë˜ì¼ ìˆ˜ìµë¥  ì˜ˆì¸¡**")
        st.metric(label="ì˜ˆì¸¡ëœ ë‹¤ìŒ ê±°ë˜ì¼ ìˆ˜ìµë¥ ", value=f"{next_day_return_pred_ml:.2f}%")

        if next_day_return_pred_ml > 0.5:
            st.success("âœ¨ RandomForest ëª¨ë¸ì€ ë‹¤ìŒ ê±°ë˜ì¼ì— **ê°•ë ¥í•œ ìƒìŠ¹**ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤!")
        elif next_day_return_pred_ml > 0:
            st.info("â¬†ï¸ RandomForest ëª¨ë¸ì€ ë‹¤ìŒ ê±°ë˜ì¼ì— **ì†Œí­ ìƒìŠ¹**ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
        elif next_day_return_pred_ml < -0.5:
            st.error("ğŸš¨ RandomForest ëª¨ë¸ì€ ë‹¤ìŒ ê±°ë˜ì¼ì— **ê°•ë ¥í•œ í•˜ë½**ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤!")
        elif next_day_return_pred_ml < 0:
            st.warning("â¬‡ï¸ RandomForest ëª¨ë¸ì€ ë‹¤ìŒ ê±°ë˜ì¼ì— **ì†Œí­ í•˜ë½**ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
        else:
            st.write("â– RandomForest ëª¨ë¸ì€ ë‹¤ìŒ ê±°ë˜ì¼ì— **í° ë³€ë™ ì—†ìŒ**ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

        # ì˜ˆì¸¡ ì‹œê°í™” (ì‹¤ì œ ìˆ˜ìµë¥ ê³¼ ì˜ˆì¸¡ ìˆ˜ìµë¥  ë¹„êµ)
        st.markdown("---")
        st.subheader("ğŸ“‰ **RandomForest ëª¨ë¸ ì˜ˆì¸¡ vs. ì‹¤ì œ ìˆ˜ìµë¥  (í…ŒìŠ¤íŠ¸ ë°ì´í„°)**")
        
        fig_rf, ax_rf = plt.subplots(figsize=(12, 6))
        ax_rf.plot(y_test_ml, label='ì‹¤ì œ ìˆ˜ìµë¥ ', color='blue', marker='o', linestyle='None', alpha=0.6)
        ax_rf.plot(y_pred_ml, label='ì˜ˆì¸¡ ìˆ˜ìµë¥ ', color='red', marker='x', linestyle='None', alpha=0.6)
        ax_rf.set_title(f"{selected_name} ({selected_code}) RandomForest ì˜ˆì¸¡ ìˆ˜ìµë¥ ")
        ax_rf.set_xlabel("ë°ì´í„° í¬ì¸íŠ¸ ì¸ë±ìŠ¤ (í…ŒìŠ¤íŠ¸ì…‹)")
        ax_rf.set_ylabel("ìˆ˜ìµë¥  (%)")
        ax_rf.legend()
        ax_rf.grid(True)
        plt.tight_layout()
        st.pyplot(fig_rf)
#########################################
# import streamlit as st
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# from datetime import datetime, timedelta
# import os

# # ë”¥ëŸ¬ë‹ ë° ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# try:
#     from sklearn.preprocessing import MinMaxScaler
#     import tensorflow as tf
#     from tensorflow.keras.models import Sequential, load_model
#     from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout
#     from tensorflow.keras.callbacks import EarlyStopping
#     # Keras Backend ê´€ë ¨ ëª¨ë“ˆì€ ë” ì´ìƒ learning_phaseë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°í•©ë‹ˆë‹¤.
#     # from tensorflow.keras import backend as K # ì´ ì¤„ì€ ì´ì œ í•„ìš” ì—†ìŠµë‹ˆë‹¤.

#     from sklearn.ensemble import RandomForestRegressor
#     from sklearn.metrics import mean_squared_error, r2_score
#     from sklearn.model_selection import train_test_split
# except ImportError:
#     st.error("""
#     **í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!**
#     ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:
#     `pip install tensorflow scikit-learn pandas matplotlib streamlit`
#     """)
#     st.stop()

# # --- Streamlit í˜ì´ì§€ ì„¤ì • ---
# st.set_page_config(layout="wide")

# st.title("ğŸ”® ì£¼ê°€ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ")
# st.markdown("ê³¼ê±° ì£¼ê°€ ë°ì´í„°, ê¸°ìˆ ì /í€ë”ë©˜í„¸ ì§€í‘œ, ê·¸ë¦¬ê³  ë”¥ëŸ¬ë‹/ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ë¯¸ë˜ ì£¼ê°€ ë° ìˆ˜ìµë¥ ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
# st.markdown("ë°©ëŒ€í•œ ë°ì´í„°ë¡œ ì¸í•´ ì‹œê°„ì´ ë‹¤ì†Œ ì˜¤ë«ë™ì•ˆ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
# # --- ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ ---
# @st.cache_data
# def calculate_bollinger_bands_pred(prices, window=20, num_std=2):
#     """ë³¼ë¦°ì € ë°´ë“œ (Bollinger Bands)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
#     rolling_mean = prices.rolling(window).mean()
#     rolling_std = prices.rolling(window).std()
#     upper_band = rolling_mean + (rolling_std * num_std)
#     lower_band = rolling_mean - (rolling_std * num_std)
#     return rolling_mean, upper_band, lower_band

# @st.cache_data
# def calculate_rsi_pred(series, period=14):
#     """ìƒëŒ€ê°•ë„ì§€ìˆ˜ (RSI)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
#     delta = series.diff()
#     gain = delta.where(delta > 0, 0)
#     loss = -delta.where(delta < 0, 0)
#     avg_gain = gain.rolling(window=period).mean()
#     avg_loss = loss.rolling(window=period).mean()
#     rs = avg_gain / avg_loss.replace(0, np.nan).fillna(0)
#     rsi = 100 - (100 / (1 + rs))
#     return rsi

# # --- LSTM ëª¨ë¸ ê´€ë ¨ í•¨ìˆ˜ ---
# # Keras 3.xì—ì„œ Monte Carlo Dropoutì„ ìœ„í•œ ì»¤ìŠ¤í…€ Dropout ë ˆì´ì–´
# # @keras.saving.register_keras_serializable() ë°ì½”ë ˆì´í„° ì¶”ê°€í•˜ì—¬ ì €ì¥/ë¡œë“œ ë¬¸ì œ ë°©ì§€
# @tf.keras.saving.register_keras_serializable()
# class MCDropout(tf.keras.layers.Dropout):
#     def call(self, inputs):
#         # Dropout ë ˆì´ì–´ì˜ 'training' ì¸ìë¥¼ Trueë¡œ ê°•ì œí•˜ì—¬ ì¶”ë¡  ì‹œì—ë„ Dropoutì´ í™œì„±í™”ë˜ë„ë¡ í•©ë‹ˆë‹¤.
#         # ì´ê²ƒì´ Monte Carlo Dropoutì˜ í•µì‹¬ì…ë‹ˆë‹¤.
#         return super().call(inputs, training=True)

# def build_lstm_model(input_shape):
#     """LSTM ëª¨ë¸ì„ ë¹Œë“œí•©ë‹ˆë‹¤. Monte Carlo Dropoutì„ ìœ„í•´ ì»¤ìŠ¤í…€ MCDropout ë ˆì´ì–´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤."""
#     model = Sequential([
#         Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape),
#         MCDropout(0.3), # ì»¤ìŠ¤í…€ MCDropout ë ˆì´ì–´ ì‚¬ìš©
#         Bidirectional(LSTM(32, return_sequences=False)),
#         MCDropout(0.3), # ì»¤ìŠ¤í…€ MCDropout ë ˆì´ì–´ ì‚¬ìš©
#         Dense(16, activation='relu'),
#         Dense(1)
#     ])
#     # ì†ì‹¤ í•¨ìˆ˜ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì¸ìŠ¤í„´ìŠ¤í™”í•˜ì—¬ ì €ì¥/ë¡œë“œ ì˜¤ë¥˜ ë°©ì§€
#     model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError()) 
#     return model

# @st.cache_resource 
# def train_and_predict_lstm_model(X_train, y_train, X_test, y_test, seq_len, n_features, selected_code, n_future_days, last_sequence, _scaler, features, n_monte_carlo_runs=100):
#     """
#     LSTM ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ë¯¸ë˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
#     Monte Carlo Dropoutì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„± êµ¬ê°„ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
#     """
#     model_path = f"lstm_model_{selected_code}.h5"
#     model = None

#     if os.path.exists(model_path):
#         try:
#             # ì»¤ìŠ¤í…€ ê°ì²´(MCDropout)ë¥¼ í¬í•¨í•˜ëŠ” ëª¨ë¸ ë¡œë“œ ì‹œ custom_objects ì¸ì í•„ìˆ˜
#             model = load_model(model_path, custom_objects={'MCDropout': MCDropout})
#             st.success("âœ… LSTM ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
#         except Exception as e:
#             st.warning(f"âš ï¸ ê¸°ì¡´ LSTM ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ëª¨ë¸ì„ ì¬í•™ìŠµí•©ë‹ˆë‹¤.")
#             os.remove(model_path) # ì†ìƒëœ ëª¨ë¸ íŒŒì¼ ì‚­ì œ
#             model = None
    
#     if model is None: # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ë˜ëŠ” íŒŒì¼ ì—†ìŒ
#         st.info("LSTM ëª¨ë¸ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")
#         model = build_lstm_model(input_shape=(seq_len, n_features))
#         with st.spinner("ğŸ”„ LSTM ëª¨ë¸ í•™ìŠµ ì¤‘ (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)..."):
#             model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test), 
#                       callbacks=[EarlyStopping(patience=7, restore_best_weights=True)], verbose=0)
#         model.save(model_path)
#         st.success("âœ… LSTM ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!")

#     def recursive_forecast_with_uncertainty(model, last_sequence, n_days, _scaler_internal, n_features, features_list, n_runs):
#         all_forecasts = [] # ëª¬í…Œì¹´ë¥¼ë¡œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

#         for _ in range(n_runs):
#             single_run_forecasts = []
#             current_seq = last_sequence.copy()
#             for __ in range(n_days):
#                 # MCDropout ë ˆì´ì–´ê°€ ì´ë¯¸ training=Trueë¡œ ì„¤ì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ predict í˜¸ì¶œ ì‹œ training ì¸ì ë¶ˆí•„ìš”
#                 pred = model.predict(current_seq.reshape(1, seq_len, n_features), verbose=0)[0][0]
#                 single_run_forecasts.append(pred)

#                 new_feature_vector = np.full(n_features, 0.0)
#                 new_feature_vector[features_list.index('Close')] = pred
#                 current_seq = np.vstack([current_seq[1:], new_feature_vector])
#             all_forecasts.append(single_run_forecasts)
        
#         all_forecasts = np.array(all_forecasts) # (n_runs, n_days) í˜•íƒœ

#         forecasts_inverse_scaled = []
#         for run_forecast in all_forecasts:
#             dummy_array_for_inverse = np.zeros((len(run_forecast), n_features))
#             dummy_array_for_inverse[:, features_list.index('Close')] = run_forecast
#             forecasts_inverse_scaled.append(_scaler_internal.inverse_transform(dummy_array_for_inverse)[:, features_list.index('Close')])

#         forecasts_inverse_scaled = np.array(forecasts_inverse_scaled) # (n_runs, n_days) í˜•íƒœ

#         mean_forecast = np.mean(forecasts_inverse_scaled, axis=0)
#         std_forecast = np.std(forecasts_inverse_scaled, axis=0)

#         upper_bound = mean_forecast + 1.96 * std_forecast
#         lower_bound = mean_forecast - 1.96 * std_forecast

#         return mean_forecast, upper_bound, lower_bound

#     mean_future_preds, upper_bound_preds, lower_bound_preds = recursive_forecast_with_uncertainty(
#         model, last_sequence, n_future_days, _scaler, n_features, features, n_monte_carlo_runs
#     )
#     return mean_future_preds, upper_bound_preds, lower_bound_preds

# # --- ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ---
# @st.cache_data
# def load_merged_data():
#     """CSV íŒŒì¼ì—ì„œ ì£¼ê°€ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
#     try:
#         current_dir = os.path.dirname(os.path.abspath(__file__))
#         root_dir = os.path.join(current_dir, '..')
#         merged_data_file_path = os.path.join(root_dir, 'merged_data_monthly_per_pbr.csv')
        
#         if not os.path.exists(merged_data_file_path):
#             merged_data_file_path = os.path.join(current_dir, 'merged_data_monthly_per_pbr.csv')


#         df = pd.read_csv(merged_data_file_path)

#         df.columns = df.columns.str.strip()

#         df['Date'] = pd.to_datetime(df['Date'])
#         df['Code'] = df['Code'].astype(str).str.zfill(6)
#         st.success(f"âœ… ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤. (ì´ {len(df)}ê°œ ë°ì´í„° í¬ì¸íŠ¸)")

#         return df
#     except FileNotFoundError:
#         st.error(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{merged_data_file_path}'")
#         st.info("ë°ì´í„° íŒŒì¼(`merged_data_monthly_per_pbr.csv`)ì´ Streamlit ì•± íŒŒì¼ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬ ë˜ëŠ” ìƒìœ„ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
#         return pd.DataFrame()
#     except Exception as e:
#         st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
#         return pd.DataFrame()

# # ì „ì²´ ë°ì´í„° ë¡œë“œ
# df_all_data = load_merged_data()

# # --- Streamlit UI ì‹œì‘ ---
# if not df_all_data.empty:
#     name_code_dict = df_all_data.drop_duplicates(subset=['Code']).set_index('Name')['Code'].to_dict()

#     if not name_code_dict:
#         st.error("ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° íŒŒì¼ì— 'Name' ë˜ëŠ” 'Code' ì»¬ëŸ¼ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì€ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
#         st.stop()

#     selected_name = st.selectbox("ğŸ”® **ì˜ˆì¸¡í•  ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”**", sorted(name_code_dict.keys()))
#     selected_code = name_code_dict[selected_name]

#     n_days = st.slider("ğŸ—“ï¸ **LSTM ì˜ˆì¸¡ ê¸°ê°„ (ë¯¸ë˜ ì¼ ìˆ˜)**", 5, 60, 30)

#     st.markdown("---")
#     st.subheader("ğŸ¤– **ë¨¸ì‹ ëŸ¬ë‹ (RandomForest) ëª¨ë¸ ì„¤ì •**")
#     st.info("RandomForest ëª¨ë¸ì€ LSTMê³¼ ë³„ë„ë¡œ ë‹¤ìŒ ê±°ë˜ì¼ì˜ ìˆ˜ìµë¥ ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

#     if st.button("ğŸš€ **ì˜ˆì¸¡ ì‹œì‘!**"):
#         with st.spinner("ë°ì´í„° ì¤€ë¹„ ë° ëª¨ë¸ ì˜ˆì¸¡ ì¤‘..."):

#             df_stock = df_all_data[df_all_data['Code'] == selected_code].copy()
#             df_stock.sort_values('Date', inplace=True)
#             df_stock.set_index('Date', inplace=True)

#             if df_stock.empty:
#                 st.error(f"ì„ íƒí•˜ì‹  ì¢…ëª© ({selected_name})ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¢…ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
#                 st.stop()

#             df_stock['RSI'] = calculate_rsi_pred(df_stock['Close'])
#             df_stock['BB_Mid'], df_stock['BB_Upper'], df_stock['BB_Lower'] = calculate_bollinger_bands_pred(df_stock['Close'])

#             if 'PER' not in df_stock.columns:
#                 st.warning("ë°ì´í„°ì— 'PER' ì»¬ëŸ¼ì´ ì—†ì–´ 0ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤. ì •í™•ë„ê°€ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
#                 df_stock['PER'] = 0.0
#             if 'PBR' not in df_stock.columns:
#                 st.warning("ë°ì´í„°ì— 'PBR' ì»¬ëŸ¼ì´ ì—†ì–´ 0ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤. ì •í™•ë„ê°€ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
#                 df_stock['PBR'] = 0.0

#             # --- 1. LSTM ëª¨ë¸ ì˜ˆì¸¡ ---
#             st.markdown("### **ğŸ“ˆ LSTM ê¸°ë°˜ ë¯¸ë˜ ì£¼ê°€ ì˜ˆì¸¡**")

#             features_lstm = ['Close', 'RSI', 'BB_Upper', 'BB_Lower', 'PER', 'PBR']
#             target_lstm = 'Close'

#             df_processed_lstm = df_stock[features_lstm + [target_lstm]].dropna()

#             seq_len = 20

#             if len(df_processed_lstm) < seq_len + 1:
#                 st.warning(f"[LSTM] ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ {selected_name}ì˜ ë¯¸ë˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ {seq_len + 1}ì¼ ì´ìƒì˜ ìœ íš¨í•œ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬ {len(df_processed_lstm)}ì¼)")
#                 mean_future_preds = None
#             else:
#                 scaler_lstm = MinMaxScaler()
#                 scaled_data_lstm = scaler_lstm.fit_transform(df_processed_lstm[features_lstm])

#                 X_lstm, y_lstm = [], []
#                 for i in range(len(scaled_data_lstm) - seq_len):
#                     X_lstm.append(scaled_data_lstm[i:i+seq_len])
#                     y_lstm.append(scaled_data_lstm[i+seq_len, features_lstm.index(target_lstm)])

#                 if not X_lstm:
#                     st.warning(f"[LSTM] ë°ì´í„° ì „ì²˜ë¦¬ í›„ ë‚¨ì€ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ {selected_name}ì˜ ë¯¸ë˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì¡°ì ˆí•˜ê±°ë‚˜ ë” ë§ì€ ë°ì´í„°ë¥¼ í™•ë³´í•´ì£¼ì„¸ìš”.")
#                     mean_future_preds = None
#                 else:
#                     X_lstm, y_lstm = np.array(X_lstm), np.array(y_lstm)

#                     test_split_ratio = 0.2
#                     split_idx_lstm = int(len(X_lstm) * (1 - test_split_ratio))
#                     X_train_lstm, X_test_lstm = X_lstm[:split_idx_lstm], X_lstm[split_idx_lstm:]
#                     y_train_lstm, y_test_lstm = y_lstm[:split_idx_lstm], y_lstm[split_idx_lstm:]
                    
#                     if len(X_test_lstm) == 0:
#                         st.warning(f"[LSTM] í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì´ ë„ˆë¬´ ì‘ì•„ ëª¨ë¸ í‰ê°€ì— ì œì•½ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
#                         if len(X_train_lstm) < seq_len + 1:
#                             st.error("í•™ìŠµ ë°ì´í„°ë„ ë¶€ì¡±í•˜ì—¬ LSTM ëª¨ë¸ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ë¥¼ í™•ë³´í•´ì£¼ì„¸ìš”.")
#                             mean_future_preds = None
#                         else:
#                             X_test_lstm, y_test_lstm = X_train_lstm[-1:], y_train_lstm[-1:] 


#                     if X_train_lstm.shape[0] > 0:
#                         last_sequence_lstm = X_lstm[-1]
#                         n_features_lstm = X_lstm.shape[2]

#                         mean_future_preds, upper_bound_preds, lower_bound_preds = train_and_predict_lstm_model(
#                             X_train_lstm, y_train_lstm, X_test_lstm, y_test_lstm, seq_len, n_features_lstm, 
#                             selected_code, n_days, last_sequence_lstm, scaler_lstm, features_lstm
#                         )
#                     else:
#                         st.error("LSTM ëª¨ë¸ì„ í•™ìŠµí•˜ê¸° ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#                         mean_future_preds = None


#             if mean_future_preds is not None:
#                 last_date = df_processed_lstm.index[-1]
#                 future_dates = [last_date + timedelta(days=i+1) for i in range(n_days)]

#                 fig_lstm, ax_lstm = plt.subplots(figsize=(12, 6))

#                 plot_df_lstm = df_processed_lstm.tail(365)
#                 ax_lstm.plot(plot_df_lstm.index, plot_df_lstm['Close'], label='ì‹¤ì œ ì£¼ê°€', color='blue')

#                 ax_lstm.plot(future_dates, mean_future_preds, label='ë¯¸ë˜ ì˜ˆì¸¡ ì£¼ê°€ (í‰ê· )', color='red', linestyle='--')
#                 ax_lstm.fill_between(future_dates, lower_bound_preds, upper_bound_preds, color='red', alpha=0.2, label='95% ì‹ ë¢° êµ¬ê°„')

#                 ax_lstm.axvline(last_date, color='gray', linestyle=':', label='base date of forecast')
#                 ax_lstm.set_title(f"{selected_name} ({selected_code}) Future Stock Price Forecast(LSTM)")
#                 ax_lstm.set_xlabel("Date")
#                 ax_lstm.set_ylabel("Price(â‚©/won)")
#                 ax_lstm.legend()
#                 ax_lstm.grid(True)
#                 plt.tight_layout()
#                 st.pyplot(fig_lstm)

#                 returns_lstm = (mean_future_preds[-1] - mean_future_preds[0]) / mean_future_preds[0] * 100
#                 st.subheader("ğŸ“ˆ **LSTM ì˜ˆì¸¡ ê¸°ê°„ ìˆ˜ìµë¥ **")
#                 st.metric(label=f"ì˜ˆì¸¡ ê¸°ê°„ ìˆ˜ìµë¥  ({future_dates[0].strftime('%Y-%m-%d')} ~ {future_dates[-1].strftime('%Y-%m-%d')})",
#                           value=f"{returns_lstm:.2f}%")
#             else:
#                 st.warning("LSTM ì˜ˆì¸¡ì„ ìœ„í•œ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


#             st.markdown("---")

#             # --- 2. RandomForestRegressor ëª¨ë¸ ì˜ˆì¸¡ ---
#             st.markdown("### **ğŸš€ RandomForest ê¸°ë°˜ ë‹¤ìŒ ê±°ë˜ì¼ ìˆ˜ìµë¥  ì˜ˆì¸¡**")

#             ml_features = ['Close', 'RSI', 'BB_Upper', 'BB_Lower', 'PER', 'PBR']
#             df_ml = df_stock[ml_features].copy()
            
#             df_ml['Next_Day_Return'] = df_ml['Close'].pct_change().shift(-1) * 100
#             df_ml.dropna(inplace=True)

#             if len(df_ml) < 20: 
#                 st.warning(f"[RandomForest] ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ìˆ˜ìµë¥  ì˜ˆì¸¡ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 20ì¼ ì´ìƒì˜ ìœ íš¨í•œ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬ {len(df_ml)}ì¼)")
#             else:
#                 X_ml = df_ml[ml_features].values
#                 y_ml = df_ml['Next_Day_Return'].values

#                 scaler_ml = MinMaxScaler()
#                 X_ml_scaled = scaler_ml.fit_transform(X_ml)

#                 test_size_ml = max(1, int(0.2 * len(X_ml_scaled))) 
#                 X_train_ml, X_test_ml = X_ml_scaled[:-test_size_ml], X_ml_scaled[-test_size_ml:]
#                 y_train_ml, y_test_ml = y_ml[:-test_size_ml], y_ml[-test_size_ml:]
                
#                 if len(X_test_ml) == 0:
#                     st.warning(f"[RandomForest] í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ëª¨ë¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
#                     X_test_ml = X_train_ml[-1:]
#                     y_test_ml = y_train_ml[-1:] 


#                 st.info("RandomForest ëª¨ë¸ í•™ìŠµ ì¤‘...")
#                 rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
#                 with st.spinner("ğŸ”„ RandomForest ëª¨ë¸ í•™ìŠµ ì¤‘..."):
#                     rf_model.fit(X_train_ml, y_train_ml)
#                 st.success("âœ… RandomForest ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

#                 y_pred_ml = rf_model.predict(X_test_ml)
                
#                 st.subheader("ğŸ“Š **RandomForest ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„°)**")
#                 st.write(f"**í‰ê·  ì œê³± ì˜¤ì°¨ (MSE)**: {mean_squared_error(y_test_ml, y_pred_ml):.2f}")
#                 st.write(f"**ê²°ì • ê³„ìˆ˜ (RÂ² Score)**: {r2_score(y_test_ml, y_pred_ml):.2f}")
#                 st.write(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ **í‰ê·  ì‹¤ì œ ìˆ˜ìµë¥ **: {np.mean(y_test_ml):.2f}%")
#                 st.write(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ **í‰ê·  ì˜ˆì¸¡ ìˆ˜ìµë¥ **: {np.mean(y_pred_ml):.2f}%")

#                 last_data_ml = X_ml_scaled[-1].reshape(1, -1)
#                 next_day_return_pred_ml = rf_model.predict(last_data_ml)[0]

#                 st.subheader("ğŸ“ˆ **RandomForest ê²°ê³¼**")
#                 st.metric(label="ì˜ˆì¸¡ëœ ìˆ˜ìµë¥ ", value=f"{next_day_return_pred_ml:.2f}%")

#                 if next_day_return_pred_ml > 0.5:
#                     st.success("âœ¨ RandomForest ëª¨ë¸ì€ **ê°•ë ¥í•œ ìƒìŠ¹**ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤!")
#                 elif next_day_return_pred_ml > 0:
#                     st.info("â¬†ï¸ RandomForest ëª¨ë¸ì€ **ì†Œí­ ìƒìŠ¹**ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
#                 elif next_day_return_pred_ml < -0.5:
#                     st.error("ğŸš¨ RandomForest ëª¨ë¸ì€ **ê°•ë ¥í•œ í•˜ë½**ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤!")
#                 elif next_day_return_pred_ml < 0:
#                     st.warning("â¬‡ï¸ RandomForest ëª¨ë¸ì€ **ì†Œí­ í•˜ë½**ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
#                 else:
#                     st.write("â– RandomForest ëª¨ë¸ì€ **í° ë³€ë™ ì—†ìŒ**ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# else:
#     st.info("ë°ì´í„° ë¡œë“œ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ ìƒë‹¨ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
