import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import os

# ë”¥ëŸ¬ë‹ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìž„í¬íŠ¸ (ê¸°ì¡´ê³¼ ë™ì¼)
try:
    from sklearn.preprocessing import MinMaxScaler
    from tensorflow.keras.models import Sequential, load_model
    from tensorflow.keras.layers import LSTM, Dense, Bidirectional
    from tensorflow.keras.callbacks import EarlyStopping
except ImportError:
    st.error("""
    **ë¯¸ëž˜ ì£¼ê°€ ì˜ˆì¸¡ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:**
    `pip install tensorflow scikit-learn`
    """)
    st.stop()


# Streamlit íŽ˜ì´ì§€ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
st.set_page_config(layout="wide")

st.title("ðŸ”® ë¯¸ëž˜ ì£¼ê°€ ì˜ˆì¸¡ (LSTM ê¸°ë°˜)")
st.markdown("ê³¼ê±° ì£¼ê°€ ë°ì´í„°ì™€ ê¸°ìˆ ì /íŽ€ë”ë©˜í„¸ ì§€í‘œë¥¼ í™œìš©í•˜ì—¬ ë¯¸ëž˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
@st.cache_data
def calculate_bollinger_bands_pred(prices, window=20, num_std=2):
    rolling_mean = prices.rolling(window).mean()
    rolling_std = prices.rolling(window).std()
    upper_band = rolling_mean + (rolling_std * num_std)
    lower_band = rolling_mean - (rolling_std * num_std)
    return rolling_mean, upper_band, lower_band

@st.cache_data
def calculate_rsi_pred(series, period=14):
    delta = series.diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.rolling(window=period).mean()
    avg_loss = loss.rolling(window=period).mean()
    rs = avg_gain / avg_loss.replace(0, np.nan)
    rsi = 100 - (100 / (1 + rs))
    return rsi

# LSTM ëª¨ë¸ ê´€ë ¨ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
def build_model(input_shape):
    model = Sequential([
        Bidirectional(LSTM(64, return_sequences=False), input_shape=input_shape),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    return model

def train_and_predict_model(X_train, y_train, X_test, y_test, seq_len, n_features, selected_code, n_future_days, last_sequence, scaler, features):
    model_path = f"model_{selected_code}.h5"
    model = None

    if os.path.exists(model_path):
        st.info("âš ï¸ ë¡œì»¬ì— ëª¨ë¸ íŒŒì¼ì´ ìžˆì§€ë§Œ, Streamlit Cloudì—ì„œëŠ” ë§¤ë²ˆ ìž¬í•™ìŠµë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
        model = load_model(model_path)
        st.success("âœ… ì €ìž¥ëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    else:
        st.info("ëª¨ë¸ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤. ìž ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")
        model = build_model(input_shape=(seq_len, n_features))
        with st.spinner("ðŸ”„ ëª¨ë¸ í•™ìŠµ ì¤‘ (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤)..."):
            model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test),
                      callbacks=[EarlyStopping(patience=5, restore_best_weights=True)], verbose=0)
        model.save(model_path)
        st.success("âœ… ëª¨ë¸ í•™ìŠµ ë° ì €ìž¥ ì™„ë£Œ")

    def recursive_forecast(model, last_sequence, n_days, scaler, n_features, features_list):
        forecasts = []
        current_seq = last_sequence.copy()

        for _ in range(n_days):
            pred = model.predict(current_seq.reshape(1, seq_len, n_features), verbose=0)[0][0]
            forecasts.append(pred)
            new_feature_vector = np.full(n_features, pred)
            current_seq = np.vstack([current_seq[1:], new_feature_vector])

        dummy_array_for_inverse = np.zeros((len(forecasts), n_features))
        dummy_array_for_inverse[:, features_list.index('Close')] = forecasts
        forecasts_scaled = scaler.inverse_transform(dummy_array_for_inverse)[:, features_list.index('Close')]
        return forecasts_scaled

    future_preds = recursive_forecast(model, last_sequence, n_future_days, scaler, n_features, features)
    return future_preds

# ---
## Streamlit UI
# ë°ì´í„° ë¡œë“œ
@st.cache_data
def load_merged_data():
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        root_dir = os.path.join(current_dir, '..')
        merged_data_file_path = os.path.join(root_dir, 'merged_data_monthly_per_pbr.csv')

        df = pd.read_csv(merged_data_file_path)

        # ---------------------- ì´ ë¶€ë¶„ì´ ì»¬ëŸ¼ ê³µë°±ì„ ì œê±°í•˜ëŠ” ì½”ë“œìž…ë‹ˆë‹¤ ----------------------
        df.columns = df.columns.str.strip()
        # -----------------------------------------------------------------------------------

        df['Date'] = pd.to_datetime(df['Date'])
        df['Code'] = df['Code'].astype(str).str.zfill(6)
        st.success(f"âœ…ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

        return df
    except FileNotFoundError:
        st.error(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì£„ì†¡í•©ë‹ˆë‹¤. ì½”ë“œë¥¼ ìˆ˜ì •ì¤‘ìž…ë‹ˆë‹¤.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()

df_all_data = load_merged_data()

# ë°ì´í„° ë¡œë“œ ì„±ê³µ ì—¬ë¶€ í™•ì¸ (ê¸°ì¡´ê³¼ ë™ì¼)
if not df_all_data.empty:
    # ì´ ì¡°ê±´ë¬¸ì—ì„œ ì´ì œ 'PER'ê³¼ 'PBR'ì„ ì œëŒ€ë¡œ ì°¾ì„ ê²ƒìž…ë‹ˆë‹¤.
    # if 'PER' not in df_all_data.columns or 'PBR' not in df_all_data.columns:
    #     st.warning("ê²½ê³ : ë°ì´í„° íŒŒì¼ì— 'PER' ë˜ëŠ” 'PBR' ì»¬ëŸ¼ì´ ì—†ì–´ ì˜ˆì¸¡ì— ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•´ë‹¹ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
    # else:
    #     st.info("ë°ì´í„° íŒŒì¼ì—ì„œ 'PER' ë° 'PBR' ì»¬ëŸ¼ì„ ì„±ê³µì ìœ¼ë¡œ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")

    name_code_dict = df_all_data.drop_duplicates(subset=['Code']).set_index('Name')['Code'].to_dict()

    if not name_code_dict:
        st.error("ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° íŒŒì¼ì— 'Name' ë˜ëŠ” 'Code' ì»¬ëŸ¼ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì€ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    selected_name = st.selectbox("ðŸ”® ì˜ˆì¸¡í•  ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”", sorted(name_code_dict.keys()))
    selected_code = name_code_dict[selected_name]

    n_days = st.slider("ì˜ˆì¸¡í•  ë¯¸ëž˜ ì¼ ìˆ˜", 5, 60, 30)

    if st.button("ðŸš€ ì£¼ê°€ ì˜ˆì¸¡ ì‹œìž‘"):
        df_stock = df_all_data[df_all_data['Code'] == selected_code].copy()
        df_stock.sort_values('Date', inplace=True)
        df_stock.set_index('Date', inplace=True)

        if df_stock.empty:
            st.error(f"ì„ íƒí•˜ì‹  ì¢…ëª© ({selected_name})ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¢…ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            st.stop()

        df_stock['RSI'] = calculate_rsi_pred(df_stock['Close'])
        df_stock['BB_Mid'], df_stock['BB_Upper'], df_stock['BB_Lower'] = calculate_bollinger_bands_pred(df_stock['Close'])

        # ì´ ë¶€ë¶„ì€ ì´ì œ ê±°ì˜ í•­ìƒ ê±´ë„ˆë›°ì–´ì§ˆ ê²ƒìž…ë‹ˆë‹¤ (ì»¬ëŸ¼ ì´ë¦„ì´ ì œëŒ€ë¡œ íŒŒì‹±ë  ê²ƒì´ë¯€ë¡œ)
        if 'PER' not in df_stock.columns:
            df_stock['PER'] = 0.0
        if 'PBR' not in df_stock.columns:
            df_stock['PBR'] = 0.0

        features = ['Close', 'RSI', 'BB_Upper', 'BB_Lower', 'PER', 'PBR']
        target = 'Close'

        df_processed = df_stock[features + [target]].dropna()

        seq_len = 20

        if len(df_processed) < seq_len + 1:
            st.warning(f"ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ {selected_name}ì˜ ë¯¸ëž˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ {seq_len + 1}ì¼ ì´ìƒì˜ ìœ íš¨í•œ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ìž¬ {len(df_processed)}ì¼)")
            st.stop()

        scaler = MinMaxScaler()
        scaled_data = scaler.fit_transform(df_processed[features])

        X, y = [], []
        for i in range(len(scaled_data) - seq_len):
            X.append(scaled_data[i:i+seq_len])
            y.append(scaled_data[i+seq_len, features.index(target)])

        if not X:
            st.warning(f"ë°ì´í„° ì „ì²˜ë¦¬ í›„ ë‚¨ì€ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ {selected_name}ì˜ ë¯¸ëž˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì¡°ì ˆí•˜ê±°ë‚˜ ë” ë§Žì€ ë°ì´í„°ë¥¼ í™•ë³´í•´ì£¼ì„¸ìš”.")
            st.stop()

        X, y = np.array(X), np.array(y)

        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

        last_sequence = X[-1]
        n_features = X.shape[2]

        future_preds = train_and_predict_model(X_train, y_train, X_test, y_test, seq_len, n_features, selected_code, n_days, last_sequence, scaler, features)

        if future_preds is None:
            st.error("ë¯¸ëž˜ ì£¼ê°€ ì˜ˆì¸¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            st.stop()

        last_date = df_processed.index[-1]
        future_dates = [last_date + timedelta(days=i+1) for i in range(n_days)]

        st.subheader("ðŸ“Š ì‹¤ì œ ì£¼ê°€ ë° ë¯¸ëž˜ ì˜ˆì¸¡ ì£¼ê°€")
        fig, ax = plt.subplots(figsize=(12, 6))

        plot_df = df_processed.tail(365)
        ax.plot(plot_df.index, plot_df['Close'], label='ì‹¤ì œ ì£¼ê°€', color='blue')

        ax.plot(future_dates, future_preds, label='ë¯¸ëž˜ ì˜ˆì¸¡ ì£¼ê°€', color='red', linestyle='--')

        ax.axvline(last_date, color='gray', linestyle=':', label='ì˜ˆì¸¡ ê¸°ì¤€ì¼')
        ax.set_title(f"{selected_name} ({selected_code}) ì£¼ê°€ ì˜ˆì¸¡")
        ax.set_xlabel("ë‚ ì§œ")
        ax.set_ylabel("ê°€ê²© (ì›)")
        ax.legend()
        ax.grid(True)
        plt.tight_layout()
        st.pyplot(fig)

        st.subheader("ðŸ“ˆ ì˜ˆì¸¡ ê¸°ê°„ ìˆ˜ìµë¥ ")
        returns = (future_preds[-1] - future_preds[0]) / future_preds[0] * 100
        st.metric(label=f"ì˜ˆì¸¡ ê¸°ê°„ ìˆ˜ìµë¥  ({future_dates[0].strftime('%Y-%m-%d')} ~ {future_dates[-1].strftime('%Y-%m-%d')})",
                  value=f"{returns:.2f}%")

else:
    st.info("ë°ì´í„° ë¡œë“œ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. íŽ˜ì´ì§€ ìƒë‹¨ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")


st.markdown("---")
st.write("### ì°¸ê³ ")
st.write("""
- **LSTM (Long Short-Term Memory):** ì‹œê³„ì—´ ë°ì´í„°ì™€ ê°™ì´ ìˆœì„œê°€ ì¤‘ìš”í•œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ê°•ì ì„ ê°€ì§„ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ í•œ ì¢…ë¥˜ìž…ë‹ˆë‹¤.
- **ì˜ˆì¸¡ì˜ í•œê³„:** ì£¼ê°€ ì˜ˆì¸¡ì€ ë³¸ì§ˆì ìœ¼ë¡œ ë¶ˆí™•ì‹¤ì„±ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ê³¼ê±° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ë¯€ë¡œ, ê¸‰ê²©í•œ ì‹œìž¥ ë³€í™”ë‚˜ ì˜ˆìƒì¹˜ ëª»í•œ ì™¸ë¶€ ìš”ì¸ì„ ë°˜ì˜í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì°¸ê³  ìžë£Œë¡œë§Œ í™œìš©í•˜ì‹œê¸° ë°”ëžë‹ˆë‹¤.
- **ëª¨ë¸ ìž¬í•™ìŠµ:** Streamlit Cloudì™€ ê°™ì€ ë°°í¬ í™˜ê²½ì—ì„œëŠ” ì•±ì´ ìž¬ì‹œìž‘ë  ë•Œë§ˆë‹¤ íŒŒì¼ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë©ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ **ë§¤ë²ˆ ëª¨ë¸ì„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•™ìŠµ**í•˜ê²Œ ë˜ë©°, ì´ëŠ” **ì‹œê°„ì´ ì˜¤ëž˜ ê±¸ë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.** ë§Œì•½ ëª¨ë¸ í•™ìŠµ ì‹œê°„ì„ ì¤„ì´ê³  ì‹¶ë‹¤ë©´, í•™ìŠµëœ ëª¨ë¸ì„ Google Driveë‚˜ S3ì™€ ê°™ì€ **ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€ì— ì €ìž¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ì‹**ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.
""")
