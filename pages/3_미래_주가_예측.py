import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import os

# ë”¥ëŸ¬ë‹ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìž„í¬íŠ¸ (ì„¤ì¹˜ í•„ìš”: pip install tensorflow scikit-learn)
try:
    from sklearn.preprocessing import MinMaxScaler
    from tensorflow.keras.models import Sequential, load_model
    from tensorflow.keras.layers import LSTM, Dense, Bidirectional
    from tensorflow.keras.callbacks import EarlyStopping
except ImportError:
    st.error("""
    **ë¯¸ëž˜ ì£¼ê°€ ì˜ˆì¸¡ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:**
    `pip install tensorflow scikit-learn`
    """)
    st.stop() # ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ê°€ ì•ˆ ë˜ì–´ ìžˆìœ¼ë©´ ì•± ì‹¤í–‰ì„ ë©ˆì¶¥ë‹ˆë‹¤.


# ---
## Streamlit íŽ˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide")

st.title("ðŸ”® ë¯¸ëž˜ ì£¼ê°€ ì˜ˆì¸¡ (LSTM ê¸°ë°˜)")
st.markdown("ê³¼ê±° ì£¼ê°€ ë°ì´í„°ì™€ ê¸°ìˆ ì /íŽ€ë”ë©˜í„¸ ì§€í‘œë¥¼ í™œìš©í•˜ì—¬ ë¯¸ëž˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# ---
## ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
@st.cache_data
def calculate_bollinger_bands_pred(prices, window=20, num_std=2):
    rolling_mean = prices.rolling(window).mean()
    rolling_std = prices.rolling(window).std()
    upper_band = rolling_mean + (rolling_std * num_std)
    lower_band = rolling_mean - (rolling_std * num_std)
    return rolling_mean, upper_band, lower_band

@st.cache_data
def calculate_rsi_pred(series, period=14):
    delta = series.diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.rolling(window=period).mean()
    avg_loss = loss.rolling(window=period).mean()
    rs = avg_gain / avg_loss.replace(0, np.nan)
    rsi = 100 - (100 / (1 + rs))
    return rsi

# ---
## LSTM ëª¨ë¸ ê´€ë ¨ í•¨ìˆ˜
def build_model(input_shape):
    model = Sequential([
        Bidirectional(LSTM(64, return_sequences=False), input_shape=input_shape),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    return model

# @st.cache_resource # ì´ ì¤„ì„ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ ì‚­ì œí•©ë‹ˆë‹¤.
def train_and_predict_model(X_train, y_train, X_test, y_test, seq_len, n_features, selected_code, n_future_days, last_sequence, scaler, features): # features ì¸ìž ì¶”ê°€
    model_path = f"model_{selected_code}.h5"
    model = None

    # Streamlit Cloudì—ì„œëŠ” ì•±ì´ ìž¬ì‹œìž‘ë  ë•Œë§ˆë‹¤ íŒŒì¼ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.
    # ë”°ë¼ì„œ ì´ ë¡œì§ì€ ë§¤ë²ˆ ìƒˆë¡œ í•™ìŠµí•˜ëŠ” íš¨ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    if os.path.exists(model_path):
        st.info("âš ï¸ ë¡œì»¬ì— ëª¨ë¸ íŒŒì¼ì´ ìžˆì§€ë§Œ, Streamlit Cloudì—ì„œëŠ” ë§¤ë²ˆ ìž¬í•™ìŠµë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
        model = load_model(model_path)
        st.success("âœ… ì €ìž¥ëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    else:
        st.info("ëª¨ë¸ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤. ìž ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")
        model = build_model(input_shape=(seq_len, n_features))
        with st.spinner("ðŸ”„ ëª¨ë¸ í•™ìŠµ ì¤‘ (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤)..."):
            model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test),
                      callbacks=[EarlyStopping(patience=5, restore_best_weights=True)], verbose=0)
        model.save(model_path)
        st.success("âœ… ëª¨ë¸ í•™ìŠµ ë° ì €ìž¥ ì™„ë£Œ")

    # ì˜ˆì¸¡ í•¨ìˆ˜
    def recursive_forecast(model, last_sequence, n_days, scaler, n_features, features_list): # features_list ì¸ìž ì¶”ê°€
        forecasts = []
        current_seq = last_sequence.copy()

        for _ in range(n_days):
            pred = model.predict(current_seq.reshape(1, seq_len, n_features), verbose=0)[0][0]
            forecasts.append(pred)

            # ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•´ ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸:
            # ì˜ˆì¸¡ëœ ì¢…ê°€(pred)ë¥¼ ìƒˆë¡œìš´ ë‚ ì˜ ëª¨ë“  íŠ¹ì§• ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë‹¨ìˆœí•œ ë°©ì‹.
            # ë” ì •í™•í•œ ì˜ˆì¸¡ì„ ìœ„í•´ì„œëŠ” ê° íŠ¹ì§•ì˜ ë¯¸ëž˜ ê°’ì„ ì˜ˆì¸¡í•˜ê±°ë‚˜, ì™¸ë¶€ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.
            new_feature_vector = np.full(n_features, pred)
            current_seq = np.vstack([current_seq[1:], new_feature_vector])

        # ì˜ˆì¸¡ê°’ì„ ì—­ ìŠ¤ì¼€ì¼ë§í•˜ì—¬ ì‹¤ì œ ì£¼ê°€ ë²”ìœ„ë¡œ ë˜ëŒë¦½ë‹ˆë‹¤.
        dummy_array_for_inverse = np.zeros((len(forecasts), n_features))
        dummy_array_for_inverse[:, features_list.index('Close')] = forecasts # ì „ë‹¬ë°›ì€ features_list ì‚¬ìš©
        forecasts_scaled = scaler.inverse_transform(dummy_array_for_inverse)[:, features_list.index('Close')]
        return forecasts_scaled

    future_preds = recursive_forecast(model, last_sequence, n_future_days, scaler, n_features, features) # features ì „ë‹¬
    return future_preds

# ---
## Streamlit UI
# ë°ì´í„° ë¡œë“œ (ê¸°ì¡´ê³¼ ë™ì¼)
@st.cache_data
def load_merged_data():
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        root_dir = os.path.join(current_dir, '..')
        merged_data_file_path = os.path.join(root_dir, 'merged_data_monthly_per_pbr.csv')

        df = pd.read_csv(merged_data_file_path)
        df['Date'] = pd.to_datetime(df['Date'])
        df['Code'] = df['Code'].astype(str).str.zfill(6)
        st.success(f"âœ… 'merged_data_monthly_per_pbr.csv' íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ê²½ë¡œ: {merged_data_file_path})")
        return df
    except FileNotFoundError:
        st.error(f"âŒ 'merged_data_monthly_per_pbr.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ˆìƒ ê²½ë¡œ: {merged_data_file_path}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()

df_all_data = load_merged_data()

# ë°ì´í„° ë¡œë“œ ì„±ê³µ ì—¬ë¶€ í™•ì¸
if not df_all_data.empty:
    st.write(f"Loaded DataFrame columns: {df_all_data.columns.tolist()}") # ì´ ì¤„ì„ ì¶”ê°€
    if 'PER' not in df_all_data.columns or 'PBR' not in df_all_data.columns:
        st.warning("ê²½ê³ : ë°ì´í„° íŒŒì¼ì— 'PER' ë˜ëŠ” 'PBR' ì»¬ëŸ¼ì´ ì—†ì–´ ì˜ˆì¸¡ì— ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•´ë‹¹ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
    else:
        st.info("ë°ì´í„° íŒŒì¼ì—ì„œ 'PER' ë° 'PBR' ì»¬ëŸ¼ì„ ì„±ê³µì ìœ¼ë¡œ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")

    name_code_dict = df_all_data.drop_duplicates(subset=['Code']).set_index('Name')['Code'].to_dict()

    if not name_code_dict:
        st.error("ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° íŒŒì¼ì— 'Name' ë˜ëŠ” 'Code' ì»¬ëŸ¼ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì€ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    selected_name = st.selectbox("ðŸ”® ì˜ˆì¸¡í•  ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”", sorted(name_code_dict.keys()))
    selected_code = name_code_dict[selected_name]

    n_days = st.slider("ì˜ˆì¸¡í•  ë¯¸ëž˜ ì¼ ìˆ˜", 5, 60, 30)

    if st.button("ðŸš€ ì£¼ê°€ ì˜ˆì¸¡ ì‹œìž‘"):
        df_stock = df_all_data[df_all_data['Code'] == selected_code].copy()
        df_stock.sort_values('Date', inplace=True)
        df_stock.set_index('Date', inplace=True) # ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •

        # ì£¼ì‹ ë°ì´í„° ë¶€ì¡± ì‹œ ì²˜ë¦¬
        if df_stock.empty:
            st.error(f"ì„ íƒí•˜ì‹  ì¢…ëª© ({selected_name})ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¢…ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            st.stop()

        # í•„ìš”í•œ ì»¬ëŸ¼ ì¶”ê°€ (PER/PBRì´ ì—†ëŠ” ê²½ìš° 0ìœ¼ë¡œ ì±„ì›€)
        df_stock['RSI'] = calculate_rsi_pred(df_stock['Close'])
        df_stock['BB_Mid'], df_stock['BB_Upper'], df_stock['BB_Lower'] = calculate_bollinger_bands_pred(df_stock['Close'])

        if 'PER' not in df_stock.columns:
            df_stock['PER'] = 0.0
        if 'PBR' not in df_stock.columns:
            df_stock['PBR'] = 0.0

        # ì˜ˆì¸¡ì— ì‚¬ìš©í•  íŠ¹ì§• (feature) ì»¬ëŸ¼ ì •ì˜
        features = ['Close', 'RSI', 'BB_Upper', 'BB_Lower', 'PER', 'PBR'] # ì´ ë¶€ë¶„ì€ `train_and_predict_model` í•¨ìˆ˜ë¡œ ì „ë‹¬ë  ê²ƒìž…ë‹ˆë‹¤.
        target = 'Close' # ì˜ˆì¸¡ ëŒ€ìƒì€ 'Close'

        # ì˜ˆì¸¡ì— í•„ìš”í•œ ë°ì´í„°ë§Œ ì„ íƒí•˜ê³  NaN ê°’ ì œê±°
        df_processed = df_stock[features + [target]].dropna()

        seq_len = 20 # LSTM ì‹œí€€ìŠ¤ ê¸¸ì´ (ê³¼ê±° 20ì¼ ë°ì´í„°ë¡œ ë‹¤ìŒ ë‚  ì˜ˆì¸¡)

        if len(df_processed) < seq_len + 1: # ìµœì†Œ ì‹œí€€ìŠ¤ ê¸¸ì´ + 1 (íƒ€ê²Ÿê°’)
            st.warning(f"ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ {selected_name}ì˜ ë¯¸ëž˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ {seq_len + 1}ì¼ ì´ìƒì˜ ìœ íš¨í•œ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ìž¬ {len(df_processed)}ì¼)")
            st.stop()

        # ìŠ¤ì¼€ì¼ë§
        scaler = MinMaxScaler()
        scaled_data = scaler.fit_transform(df_processed[features])

        X, y = [], []
        # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
        for i in range(len(scaled_data) - seq_len):
            X.append(scaled_data[i:i+seq_len]) # ê³¼ê±° seq_lenì¼ê°„ì˜ íŠ¹ì§• ì‹œí€€ìŠ¤
            y.append(scaled_data[i+seq_len, features.index(target)]) # ì‹œí€€ìŠ¤ ë‹¤ìŒ ë‚ ì˜ íƒ€ê²Ÿ (Close) ê°’

        if not X: # Xê°€ ë¹„ì–´ìžˆì„ ê²½ìš° (ë°ì´í„°ê°€ ë„ˆë¬´ ì ì–´ ì‹œí€€ìŠ¤ ìƒì„±ì´ ì•ˆ ë  ë•Œ)
            st.warning(f"ë°ì´í„° ì „ì²˜ë¦¬ í›„ ë‚¨ì€ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ {selected_name}ì˜ ë¯¸ëž˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì¡°ì ˆí•˜ê±°ë‚˜ ë” ë§Žì€ ë°ì´í„°ë¥¼ í™•ë³´í•´ì£¼ì„¸ìš”.")
            st.stop()

        X, y = np.array(X), np.array(y)

        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ (ì‹œê³„ì—´ ë°ì´í„°ì´ë¯€ë¡œ ìˆœì„œë¥¼ ìœ ì§€í•˜ë©° ë¶„ë¦¬)
        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

        last_sequence = X[-1] # ì˜ˆì¸¡ì˜ ì‹œìž‘ì ì´ ë  ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤
        n_features = X.shape[2] # ëª¨ë¸ ìž…ë ¥ íŠ¹ì§•ì˜ ê°œìˆ˜

        # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ í•¨ìˆ˜ í˜¸ì¶œ
        # train_and_predict_model í•¨ìˆ˜ì— `features` ë¦¬ìŠ¤íŠ¸ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
        future_preds = train_and_predict_model(X_train, y_train, X_test, y_test, seq_len, n_features, selected_code, n_days, last_sequence, scaler, features)

        if future_preds is None: # ëª¨ë¸ í•™ìŠµ/ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ (ì˜ˆì™¸ ì²˜ë¦¬)
            st.error("ë¯¸ëž˜ ì£¼ê°€ ì˜ˆì¸¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            st.stop()

        # ì˜ˆì¸¡ ë‚ ì§œ ìƒì„±
        last_date = df_processed.index[-1]
        future_dates = [last_date + timedelta(days=i+1) for i in range(n_days)]

        # ---
        ## ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
        st.subheader("ðŸ“Š ì‹¤ì œ ì£¼ê°€ ë° ë¯¸ëž˜ ì˜ˆì¸¡ ì£¼ê°€")
        fig, ax = plt.subplots(figsize=(12, 6))

        # ì‹¤ì œ ì£¼ê°€ (ìµœê·¼ ì¼ë¶€ë§Œ ì‹œê°í™”í•˜ì—¬ ì˜ˆì¸¡ê³¼ ë¹„êµ ìš©ì´)
        plot_df = df_processed.tail(365) # ìµœê·¼ 1ë…„(365ì¼)ì¹˜ë§Œ í‘œì‹œ
        ax.plot(plot_df.index, plot_df['Close'], label='ì‹¤ì œ ì£¼ê°€', color='blue')

        # ì˜ˆì¸¡ ì£¼ê°€
        ax.plot(future_dates, future_preds, label='ë¯¸ëž˜ ì˜ˆì¸¡ ì£¼ê°€', color='red', linestyle='--')

        ax.axvline(last_date, color='gray', linestyle=':', label='ì˜ˆì¸¡ ê¸°ì¤€ì¼')
        ax.set_title(f"{selected_name} ({selected_code}) ì£¼ê°€ ì˜ˆì¸¡")
        ax.set_xlabel("ë‚ ì§œ")
        ax.set_ylabel("ê°€ê²© (ì›)")
        ax.legend()
        ax.grid(True)
        plt.tight_layout()
        st.pyplot(fig)

        st.subheader("ðŸ“ˆ ì˜ˆì¸¡ ê¸°ê°„ ìˆ˜ìµë¥ ")
        returns = (future_preds[-1] - future_preds[0]) / future_preds[0] * 100
        st.metric(label=f"ì˜ˆì¸¡ ê¸°ê°„ ìˆ˜ìµë¥  ({future_dates[0].strftime('%Y-%m-%d')} ~ {future_dates[-1].strftime('%Y-%m-%d')})",
                  value=f"{returns:.2f}%")

else:
    # ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë©”ì‹œì§€ (load_merged_data í•¨ìˆ˜ì—ì„œ ì´ë¯¸ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥ë¨)
    st.info("ë°ì´í„° ë¡œë“œ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. íŽ˜ì´ì§€ ìƒë‹¨ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")


st.markdown("---")
st.write("### ì°¸ê³ ")
st.write("""
- **LSTM (Long Short-Term Memory):** ì‹œê³„ì—´ ë°ì´í„°ì™€ ê°™ì´ ìˆœì„œê°€ ì¤‘ìš”í•œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ê°•ì ì„ ê°€ì§„ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ í•œ ì¢…ë¥˜ìž…ë‹ˆë‹¤.
- **ì˜ˆì¸¡ì˜ í•œê³„:** ì£¼ê°€ ì˜ˆì¸¡ì€ ë³¸ì§ˆì ìœ¼ë¡œ ë¶ˆí™•ì‹¤ì„±ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ê³¼ê±° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ë¯€ë¡œ, ê¸‰ê²©í•œ ì‹œìž¥ ë³€í™”ë‚˜ ì˜ˆìƒì¹˜ ëª»í•œ ì™¸ë¶€ ìš”ì¸ì„ ë°˜ì˜í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì°¸ê³  ìžë£Œë¡œë§Œ í™œìš©í•˜ì‹œê¸° ë°”ëžë‹ˆë‹¤.
- **ëª¨ë¸ ìž¬í•™ìŠµ:** Streamlit Cloudì™€ ê°™ì€ ë°°í¬ í™˜ê²½ì—ì„œëŠ” ì•±ì´ ìž¬ì‹œìž‘ë  ë•Œë§ˆë‹¤ íŒŒì¼ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë©ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ **ë§¤ë²ˆ ëª¨ë¸ì„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•™ìŠµ**í•˜ê²Œ ë˜ë©°, ì´ëŠ” **ì‹œê°„ì´ ì˜¤ëž˜ ê±¸ë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.** ë§Œì•½ ëª¨ë¸ í•™ìŠµ ì‹œê°„ì„ ì¤„ì´ê³  ì‹¶ë‹¤ë©´, í•™ìŠµëœ ëª¨ë¸ì„ Google Driveë‚˜ S3ì™€ ê°™ì€ **ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€ì— ì €ìž¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ì‹**ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.
""")
