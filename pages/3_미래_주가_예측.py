# streamlit_test/pages/3_ë¯¸ëž˜_ì£¼ê°€_ì˜ˆì¸¡.py
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import os # os ëª¨ë“ˆ ìž„í¬íŠ¸

# ë”¥ëŸ¬ë‹ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìž„í¬íŠ¸ (ì„¤ì¹˜ í•„ìš”: pip install tensorflow scikit-learn)
try:
    from sklearn.preprocessing import MinMaxScaler
    from tensorflow.keras.models import Sequential, load_model
    from tensorflow.keras.layers import LSTM, Dense, Bidirectional
    from tensorflow.keras.callbacks import EarlyStopping
except ImportError:
    st.error("""
    **ë¯¸ëž˜ ì£¼ê°€ ì˜ˆì¸¡ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:**
    `pip install tensorflow scikit-learn`
    """)
    st.stop() # ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ê°€ ì•ˆ ë˜ì–´ ìžˆìœ¼ë©´ ì•± ì‹¤í–‰ì„ ë©ˆì¶¥ë‹ˆë‹¤.


# ---
## Streamlit íŽ˜ì´ì§€ ì„¤ì •
# st.set_page_config()ëŠ” ë°˜ë“œì‹œ íŒŒì¼ì˜ ê°€ìž¥ ì²« ë²ˆì§¸ Streamlit ëª…ë ¹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
st.set_page_config(layout="wide")

st.title("ðŸ”® ë¯¸ëž˜ ì£¼ê°€ ì˜ˆì¸¡ (LSTM ê¸°ë°˜)")
st.markdown("ê³¼ê±° ì£¼ê°€ ë°ì´í„°ì™€ ê¸°ìˆ ì /íŽ€ë”ë©˜í„¸ ì§€í‘œë¥¼ í™œìš©í•˜ì—¬ ë¯¸ëž˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# ---
## ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° í•¨ìˆ˜
@st.cache_data
def calculate_bollinger_bands_pred(prices, window=20, num_std=2):
    rolling_mean = prices.rolling(window).mean()
    rolling_std = prices.rolling(window).std()
    upper_band = rolling_mean + (rolling_std * num_std)
    lower_band = rolling_mean - (rolling_std * num_std)
    return rolling_mean, upper_band, lower_band

@st.cache_data
def calculate_rsi_pred(series, period=14):
    delta = series.diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.rolling(window=period).mean()
    avg_loss = loss.rolling(window=period).mean()
    rs = avg_gain / avg_loss.replace(0, np.nan) # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì˜¤ë¥˜ ë°©ì§€
    rsi = 100 - (100 / (1 + rs))
    return rsi

# ---
## LSTM ëª¨ë¸ ê´€ë ¨ í•¨ìˆ˜
def build_model(input_shape):
    model = Sequential([
        Bidirectional(LSTM(64, return_sequences=False), input_shape=input_shape),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    return model

#@st.cache_resource # ëª¨ë¸ í•™ìŠµ ê²°ê³¼ë¥¼ ìºì‹± (ìž¬ì‹¤í–‰ ì‹œ ìž¬í•™ìŠµ ë°©ì§€)
def train_and_predict_model(X_train, y_train, X_test, y_test, seq_len, n_features, selected_code, n_future_days, last_sequence, scaler):
    model_path = f"model_{selected_code}.h5"
    model = None

    if os.path.exists(model_path):
        model = load_model(model_path)
        st.success("âœ… ì €ìž¥ëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    else:
        st.info("ëª¨ë¸ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤. ìž ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")
        model = build_model(input_shape=(seq_len, n_features))
        with st.spinner("ðŸ”„ ëª¨ë¸ í•™ìŠµ ì¤‘ (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤)..."):
            model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test),
                      callbacks=[EarlyStopping(patience=5, restore_best_weights=True)], verbose=0)
        model.save(model_path)
        st.success("âœ… ëª¨ë¸ í•™ìŠµ ë° ì €ìž¥ ì™„ë£Œ")

    # ì˜ˆì¸¡ í•¨ìˆ˜
    def recursive_forecast(model, last_sequence, n_days, scaler, n_features):
        forecasts = []
        current_seq = last_sequence.copy()

        for _ in range(n_days):
            # LSTM ëª¨ë¸ì€ 3D ìž…ë ¥ (samples, timesteps, features)ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤.
            # current_seqëŠ” (timesteps, features) í˜•íƒœì´ë¯€ë¡œ, ì•žì— samples ì°¨ì›ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
            pred = model.predict(current_seq.reshape(1, seq_len, n_features), verbose=0)[0][0]
            forecasts.append(pred)

            # ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•´ ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸:
            # ê°€ìž¥ ê°„ë‹¨í•œ ë°©ë²•ì€ ì˜ˆì¸¡ëœ ì¢…ê°€(pred)ë¥¼ ìƒˆë¡œìš´ ë‚ ì˜ ëª¨ë“  íŠ¹ì§• ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤.
            # í•˜ì§€ë§Œ ì´ëŠ” ë‹¤ë¥¸ íŠ¹ì§•(RSI, BB, PER, PBR)ì´ ì¢…ê°€ì™€ í•¨ê»˜ ì›€ì§ì¸ë‹¤ê³  ê°€ì •í•˜ëŠ” ë§¤ìš° ë‹¨ìˆœí•œ ë°©ì‹ìž…ë‹ˆë‹¤.
            # ë” ì •í™•í•œ ì˜ˆì¸¡ì„ ìœ„í•´ì„œëŠ” ê° íŠ¹ì§•ì˜ ë¯¸ëž˜ ê°’ì„ ì˜ˆì¸¡í•˜ê±°ë‚˜, ì™¸ë¶€ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.
            # ì—¬ê¸°ì„œëŠ” íŽ¸ì˜ë¥¼ ìœ„í•´ ì˜ˆì¸¡ëœ ì¢…ê°€ë¡œ ëª¨ë“  íŠ¹ì§• ë²¡í„°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
            new_feature_vector = np.full(n_features, pred)
            current_seq = np.vstack([current_seq[1:], new_feature_vector]) # ê°€ìž¥ ì˜¤ëž˜ëœ ë°ì´í„°ë¥¼ ë²„ë¦¬ê³  ìƒˆ ë²¡í„° ì¶”ê°€

        # ì˜ˆì¸¡ê°’ì„ ì—­ ìŠ¤ì¼€ì¼ë§í•˜ì—¬ ì‹¤ì œ ì£¼ê°€ ë²”ìœ„ë¡œ ë˜ëŒë¦½ë‹ˆë‹¤.
        # ìŠ¤ì¼€ì¼ëŸ¬ëŠ” fit_transformë  ë•Œ ì‚¬ìš©ëœ íŠ¹ì§•ë“¤ì˜ ìˆœì„œë¥¼ ê¸°ì–µí•©ë‹ˆë‹¤.
        # ì˜ˆì¸¡ê°’ì€ ë‹¨ì¼ ì»¬ëŸ¼ì´ë¯€ë¡œ, ìŠ¤ì¼€ì¼ëŸ¬ê°€ ê¸°ëŒ€í•˜ëŠ” 2D í˜•íƒœë¡œ ë§žì¶°ì¤€ í›„ ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        # (ì›ëž˜ 'Close'ê°€ features ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ì˜€ìœ¼ë¯€ë¡œ, ì˜ˆì¸¡ê°’ë„ Closeì˜ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.)
        dummy_array_for_inverse = np.zeros((len(forecasts), n_features))
        dummy_array_for_inverse[:, features.index('Close')] = forecasts # ì˜ˆì¸¡ê°’ì„ 'Close' ìœ„ì¹˜ì—ë§Œ ë„£ê¸°
        forecasts_scaled = scaler.inverse_transform(dummy_array_for_inverse)[:, features.index('Close')]
        return forecasts_scaled

    future_preds = recursive_forecast(model, last_sequence, n_future_days, scaler, n_features)
    return future_preds

# ---
## Streamlit UI
# ë°ì´í„° ë¡œë“œ
@st.cache_data
def load_merged_data():
    try:
        # âš ï¸ ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ìž…ë‹ˆë‹¤!
        # í˜„ìž¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ (3_ë¯¸ëž˜_ì£¼ê°€_ì˜ˆì¸¡.py)ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ
        # 'merged_data_monthly_per_pbr.csv' íŒŒì¼ì´ ìžˆëŠ” ìƒìœ„ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì—¬ ê²½ë¡œë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
        current_dir = os.path.dirname(os.path.abspath(__file__))
        # ì˜ˆë¥¼ ë“¤ì–´, ìŠ¤í¬ë¦½íŠ¸ê°€ 'streamlit_test/pages/'ì— ìžˆë‹¤ë©´, root_dirì€ 'streamlit_test/'ê°€ ë©ë‹ˆë‹¤.
        root_dir = os.path.join(current_dir, '..')
        merged_data_file_path = os.path.join(root_dir, 'merged_data_monthly_per_pbr.csv')

        df = pd.read_csv(merged_data_file_path) # ìˆ˜ì •ëœ ê²½ë¡œ ì‚¬ìš©
        df['Date'] = pd.to_datetime(df['Date'])
        df['Code'] = df['Code'].astype(str).str.zfill(6) # ì¢…ëª©ì½”ë“œ 6ìžë¦¬ë¡œ ì±„ìš°ê¸°
        st.success(f"âœ… 'merged_data_monthly_per_pbr.csv' íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ê²½ë¡œ: {merged_data_file_path})")
        return df
    except FileNotFoundError:
        st.error(f"âŒ 'merged_data_monthly_per_pbr.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ˆìƒ ê²½ë¡œ: {merged_data_file_path}")
        return pd.DataFrame() # ë¹ˆ ë°ì´í„°í”„ë ˆìž„ì„ ë°˜í™˜í•˜ì—¬ ì´í›„ ì˜¤ë¥˜ ë°©ì§€
    except Exception as e: # íŒŒì¼ì„ ì°¾ì•˜ì§€ë§Œ ì½ëŠ” ì¤‘ ë‹¤ë¥¸ ì˜¤ë¥˜ ë°œìƒ ì‹œ
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame() # ë¹ˆ ë°ì´í„°í”„ë ˆìž„ì„ ë°˜í™˜í•˜ì—¬ ì´í›„ ì˜¤ë¥˜ ë°©ì§€

df_all_data = load_merged_data()

# ë°ì´í„° ë¡œë“œ ì„±ê³µ ì—¬ë¶€ í™•ì¸
if not df_all_data.empty:
    # PER/PBR ì»¬ëŸ¼ ì¡´ìž¬ ì—¬ë¶€ í™•ì¸ ë¡œì§
    # ì»¬ëŸ¼ì´ ì¡´ìž¬í•˜ë©´ ê²½ê³  ë©”ì‹œì§€ê°€ ëœ¨ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
    if 'PER' not in df_all_data.columns or 'PBR' not in df_all_data.columns:
        st.warning("ê²½ê³ : ë°ì´í„° íŒŒì¼ì— 'PER' ë˜ëŠ” 'PBR' ì»¬ëŸ¼ì´ ì—†ì–´ ì˜ˆì¸¡ì— ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•´ë‹¹ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
    else:
        st.info("ë°ì´í„° íŒŒì¼ì—ì„œ 'PER' ë° 'PBR' ì»¬ëŸ¼ì„ ì„±ê³µì ìœ¼ë¡œ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")

    name_code_dict = df_all_data.drop_duplicates(subset=['Code']).set_index('Name')['Code'].to_dict()

    # name_code_dictê°€ ë¹„ì–´ìžˆì„ ìˆ˜ ìžˆëŠ” ê²½ìš° (ë°ì´í„°í”„ë ˆìž„ì— ìœ íš¨í•œ Name/Codeê°€ ì—†ì„ ë•Œ) ì²˜ë¦¬
    if not name_code_dict:
        st.error("ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° íŒŒì¼ì— 'Name' ë˜ëŠ” 'Code' ì»¬ëŸ¼ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì€ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    selected_name = st.selectbox("ðŸ”® ì˜ˆì¸¡í•  ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”", sorted(name_code_dict.keys()))
    selected_code = name_code_dict[selected_name]

    n_days = st.slider("ì˜ˆì¸¡í•  ë¯¸ëž˜ ì¼ ìˆ˜", 5, 60, 30)

    if st.button("ðŸš€ ì£¼ê°€ ì˜ˆì¸¡ ì‹œìž‘"):
        df_stock = df_all_data[df_all_data['Code'] == selected_code].copy()
        df_stock.sort_values('Date', inplace=True)
        df_stock.set_index('Date', inplace=True) # ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •

        # ì£¼ì‹ ë°ì´í„° ë¶€ì¡± ì‹œ ì²˜ë¦¬
        if df_stock.empty:
            st.error(f"ì„ íƒí•˜ì‹  ì¢…ëª© ({selected_name})ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¢…ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            st.stop()

        # í•„ìš”í•œ ì»¬ëŸ¼ ì¶”ê°€ (PER/PBRì´ ì—†ëŠ” ê²½ìš° 0ìœ¼ë¡œ ì±„ì›€)
        df_stock['RSI'] = calculate_rsi_pred(df_stock['Close'])
        df_stock['BB_Mid'], df_stock['BB_Upper'], df_stock['BB_Lower'] = calculate_bollinger_bands_pred(df_stock['Close'])

        # PER/PBR ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ìš°ëŠ” ë¡œì§ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì•ˆì „ ìž¥ì¹˜)
        if 'PER' not in df_stock.columns:
            df_stock['PER'] = 0.0
        if 'PBR' not in df_stock.columns:
            df_stock['PBR'] = 0.0

        # ì˜ˆì¸¡ì— ì‚¬ìš©í•  íŠ¹ì§• (feature) ì»¬ëŸ¼ ì •ì˜
        features = ['Close', 'RSI', 'BB_Upper', 'BB_Lower', 'PER', 'PBR']
        target = 'Close' # ì˜ˆì¸¡ ëŒ€ìƒì€ 'Close'

        # ì˜ˆì¸¡ì— í•„ìš”í•œ ë°ì´í„°ë§Œ ì„ íƒí•˜ê³  NaN ê°’ ì œê±°
        df_processed = df_stock[features + [target]].dropna()

        seq_len = 20 # LSTM ì‹œí€€ìŠ¤ ê¸¸ì´ (ê³¼ê±° 20ì¼ ë°ì´í„°ë¡œ ë‹¤ìŒ ë‚  ì˜ˆì¸¡)

        if len(df_processed) < seq_len + 1: # ìµœì†Œ ì‹œí€€ìŠ¤ ê¸¸ì´ + 1 (íƒ€ê²Ÿê°’)
            st.warning(f"ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ {selected_name}ì˜ ë¯¸ëž˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ {seq_len + 1}ì¼ ì´ìƒì˜ ìœ íš¨í•œ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ìž¬ {len(df_processed)}ì¼)")
            st.stop()

        # ìŠ¤ì¼€ì¼ë§
        scaler = MinMaxScaler()
        # ëª¨ë“  íŠ¹ì§•ì„ ë™ì‹œì— ìŠ¤ì¼€ì¼ë§ (í•™ìŠµì— ì‚¬ìš©ë  ëª¨ë“  íŠ¹ì§•)
        scaled_data = scaler.fit_transform(df_processed[features])

        X, y = [], []
        # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
        for i in range(len(scaled_data) - seq_len):
            X.append(scaled_data[i:i+seq_len]) # ê³¼ê±° seq_lenì¼ê°„ì˜ íŠ¹ì§• ì‹œí€€ìŠ¤
            y.append(scaled_data[i+seq_len, features.index(target)]) # ì‹œí€€ìŠ¤ ë‹¤ìŒ ë‚ ì˜ íƒ€ê²Ÿ (Close) ê°’

        if not X: # Xê°€ ë¹„ì–´ìžˆì„ ê²½ìš° (ë°ì´í„°ê°€ ë„ˆë¬´ ì ì–´ ì‹œí€€ìŠ¤ ìƒì„±ì´ ì•ˆ ë  ë•Œ)
            st.warning(f"ë°ì´í„° ì „ì²˜ë¦¬ í›„ ë‚¨ì€ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ {selected_name}ì˜ ë¯¸ëž˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì¡°ì ˆí•˜ê±°ë‚˜ ë” ë§Žì€ ë°ì´í„°ë¥¼ í™•ë³´í•´ì£¼ì„¸ìš”.")
            st.stop()

        X, y = np.array(X), np.array(y)

        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ (ì‹œê³„ì—´ ë°ì´í„°ì´ë¯€ë¡œ ìˆœì„œë¥¼ ìœ ì§€í•˜ë©° ë¶„ë¦¬)
        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

        last_sequence = X[-1] # ì˜ˆì¸¡ì˜ ì‹œìž‘ì ì´ ë  ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤
        n_features = X.shape[2] # ëª¨ë¸ ìž…ë ¥ íŠ¹ì§•ì˜ ê°œìˆ˜

        # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ í•¨ìˆ˜ í˜¸ì¶œ
        future_preds = train_and_predict_model(X_train, y_train, X_test, y_test, seq_len, n_features, selected_code, n_days, last_sequence, scaler)

        if future_preds is None: # ëª¨ë¸ í•™ìŠµ/ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ (ì˜ˆì™¸ ì²˜ë¦¬)
            st.error("ë¯¸ëž˜ ì£¼ê°€ ì˜ˆì¸¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            st.stop()

        # ì˜ˆì¸¡ ë‚ ì§œ ìƒì„±
        last_date = df_processed.index[-1]
        future_dates = [last_date + timedelta(days=i+1) for i in range(n_days)]

        # ---
        ## ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
        st.subheader("ðŸ“Š ì‹¤ì œ ì£¼ê°€ ë° ë¯¸ëž˜ ì˜ˆì¸¡ ì£¼ê°€")
        fig, ax = plt.subplots(figsize=(12, 6))

        # ì‹¤ì œ ì£¼ê°€ (ìµœê·¼ ì¼ë¶€ë§Œ ì‹œê°í™”í•˜ì—¬ ì˜ˆì¸¡ê³¼ ë¹„êµ ìš©ì´)
        # ì „ì²´ ë°ì´í„°ê°€ ë„ˆë¬´ ë§Žìœ¼ë©´ ê·¸ëž˜í”„ê°€ ë³µìž¡í•´ì§€ë¯€ë¡œ ìµœê·¼ 1ë…„(365ì¼)ì¹˜ë§Œ í‘œì‹œ
        plot_df = df_processed.tail(365)
        ax.plot(plot_df.index, plot_df['Close'], label='ì‹¤ì œ ì£¼ê°€', color='blue')

        # ì˜ˆì¸¡ ì£¼ê°€
        ax.plot(future_dates, future_preds, label='ë¯¸ëž˜ ì˜ˆì¸¡ ì£¼ê°€', color='red', linestyle='--')

        ax.axvline(last_date, color='gray', linestyle=':', label='ì˜ˆì¸¡ ê¸°ì¤€ì¼')
        ax.set_title(f"{selected_name} ({selected_code}) ì£¼ê°€ ì˜ˆì¸¡")
        ax.set_xlabel("ë‚ ì§œ")
        ax.set_ylabel("ê°€ê²© (ì›)")
        ax.legend()
        ax.grid(True)
        plt.tight_layout() # ê·¸ëž˜í”„ ë ˆì´ì•„ì›ƒ ìžë™ ì¡°ì •
        st.pyplot(fig)

        st.subheader("ðŸ“ˆ ì˜ˆì¸¡ ê¸°ê°„ ìˆ˜ìµë¥ ")
        returns = (future_preds[-1] - future_preds[0]) / future_preds[0] * 100
        st.metric(label=f"ì˜ˆì¸¡ ê¸°ê°„ ìˆ˜ìµë¥  ({future_dates[0].strftime('%Y-%m-%d')} ~ {future_dates[-1].strftime('%Y-%m-%d')})",
                  value=f"{returns:.2f}%")

else:
    # ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë©”ì‹œì§€ (load_merged_data í•¨ìˆ˜ì—ì„œ ì´ë¯¸ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥ë¨)
    st.info("ë°ì´í„° ë¡œë“œ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. íŽ˜ì´ì§€ ìƒë‹¨ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")


st.markdown("---")
st.write("### ì°¸ê³ ")
st.write("""
- **LSTM (Long Short-Term Memory):** ì‹œê³„ì—´ ë°ì´í„°ì™€ ê°™ì´ ìˆœì„œê°€ ì¤‘ìš”í•œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ê°•ì ì„ ê°€ì§„ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ í•œ ì¢…ë¥˜ìž…ë‹ˆë‹¤.
- **ì˜ˆì¸¡ì˜ í•œê³„:** ì£¼ê°€ ì˜ˆì¸¡ì€ ë³¸ì§ˆì ìœ¼ë¡œ ë¶ˆí™•ì‹¤ì„±ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ê³¼ê±° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ë¯€ë¡œ, ê¸‰ê²©í•œ ì‹œìž¥ ë³€í™”ë‚˜ ì˜ˆìƒì¹˜ ëª»í•œ ì™¸ë¶€ ìš”ì¸ì„ ë°˜ì˜í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì°¸ê³  ìžë£Œë¡œë§Œ í™œìš©í•˜ì‹œê¸° ë°”ëžë‹ˆë‹¤.
- **ëª¨ë¸ ìž¬í•™ìŠµ:** ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì¶”ê°€ë˜ê±°ë‚˜ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ëª¨ë¸ì„ ìž¬í•™ìŠµí•˜ëŠ” ê²ƒì´ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ë†’ì´ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
""")
